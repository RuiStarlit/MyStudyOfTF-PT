{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os\n",
    "import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = sorted(glob.glob('../../stock_price/train/*.hdf'))\n",
    "# train_f.remove('../stock_price/train/20190425_20190510.hdf')\n",
    "test_f = sorted(glob.glob('../../stock_price/test/*.hdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../stock_price/train\\\\20190401_20190412.hdf',\n",
       " '../../stock_price/train\\\\20190412_20190424.hdf',\n",
       " '../../stock_price/train\\\\20190425_20190510.hdf',\n",
       " '../../stock_price/train\\\\20190510_20190522.hdf',\n",
       " '../../stock_price/train\\\\20190523_20190604.hdf',\n",
       " '../../stock_price/train\\\\20190604_20190617.hdf',\n",
       " '../../stock_price/train\\\\20190617_20190628.hdf',\n",
       " '../../stock_price/train\\\\20190628_20190710.hdf',\n",
       " '../../stock_price/train\\\\20190710_20190723.hdf',\n",
       " '../../stock_price/train\\\\20190723_20190731.hdf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tick_hour_minute_str(tick):\n",
    "    dt = datetime.datetime(1, 1, 1) + datetime.timedelta(microseconds=tick / 10)\n",
    "    return dt.strftime(\"%H%M\")\n",
    "\n",
    "def get_tick_date_time(tick):\n",
    "    dt = datetime.datetime(1, 1, 1) + datetime.timedelta(microseconds=tick / 10)\n",
    "    return dt\n",
    "\n",
    "def get_tick_weekday(tick):\n",
    "    dt = datetime.datetime(1, 1, 1) + datetime.timedelta(microseconds=tick / 10)\n",
    "    return dt.weekday()\n",
    "\n",
    "def encode_time(dt):\n",
    "    # 对时间数据编码 周一到周五 和上下午 一共5*2=10个状态\n",
    "    hm = int(dt.strftime(\"%H%M\"))\n",
    "    if hm <= 1130:\n",
    "        hm = 0\n",
    "    elif 1300 <= hm and hm <= 1500:\n",
    "        hm = 1\n",
    "    else:\n",
    "        raise ValueError('时间数据出错')\n",
    "    wd = dt.weekday()\n",
    "    return wd * 10 + hm\n",
    "\n",
    "# 转化为可以作用于numpy的函数\n",
    "get_hour_minute_str_ = np.frompyfunc(get_tick_hour_minute_str, 1, 1)\n",
    "get_tick_date_time_ = np.frompyfunc(get_tick_date_time, 1, 1)\n",
    "get_tick_weekday_ = np.frompyfunc(get_tick_weekday, 1, 1)\n",
    "encode_time_ = np.frompyfunc(encode_time, 1, 1)\n",
    "\n",
    "categories = [np.array([0, 1, 10, 11, 20, 21, 30, 31, 40, 41],\n",
    "                       dtype=object)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_data_file(file_list, func, n_cores=4):\n",
    "    file_split = np.array_split(file_list, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    print('start pool map:', len(file_split))\n",
    "    result_files = pool.map(func, file_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "def data_pro_parallelize(hdf_files):\n",
    "    data_list = []\n",
    "    for f in hdf_files.tolist():\n",
    "        data_pro(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset_p():\n",
    "    def __init__(self, file_name, label_len=10, initpoint=1000):\n",
    "        self.name = file_name\n",
    "        self.__read_data__()\n",
    "        self.n = self.y.shape[0]\n",
    "        self.indexes = np.arange(self.n)\n",
    "        self.mask = list(range(15))  # [1, 3, 4, 5, 6, 7, 8, 9]# [0, 2, 10, 11, 12, 13, 14]\n",
    "        self.label_len = label_len\n",
    "        self.shift = 9\n",
    "        self.initpoint = initpoint\n",
    "\n",
    "    def __read_data__(self):\n",
    "        f = h5py.File(self.name, 'r')\n",
    "        self.x = f['x'][:]\n",
    "        self.y = f['y'][:]\n",
    "        self.ts = f['timestamp'][:]\n",
    "        f.close()\n",
    "        codedtime = encode_time_(get_tick_date_time_(self.ts))\n",
    "        codedtime = codedtime.reshape(len(codedtime), 1)\n",
    "        onehot_encoder = OneHotEncoder(categories=categories, sparse=False)\n",
    "        self.codedtime = onehot_encoder.fit_transform(codedtime)\n",
    "        self.codedtime = self.codedtime[:, :, np.newaxis]\n",
    "\n",
    "    def __call__(self):\n",
    "        batch_index = self.indexes\n",
    "\n",
    "        # 向过去取历史时间序列\n",
    "\n",
    "        batch_index = self.indexes[0 + self.shift + self.label_len: ]\n",
    "        Y = self.y[batch_index]\n",
    "        y_len = batch_index.shape[0]\n",
    "        temp = self.y[0: ]\n",
    "        for j in range(self.label_len + self.shift):\n",
    "            Y = np.hstack((temp[-1 - j - y_len: -1 - j], Y))\n",
    "\n",
    "        pY = np.empty((Y.shape), dtype=np.float32)\n",
    "        pY[:, 0] = self.initpoint\n",
    "        for j in range(1, self.label_len + self.shift + 1):\n",
    "            pY[:, j] = (Y[:, j] / 100 + 1) * pY[:, j - 1]\n",
    "\n",
    "        # 计算价格\n",
    "\n",
    "        Y = Y[:, :, np.newaxis]\n",
    "        pY = pY[:, :, np.newaxis]\n",
    "        Y = np.concatenate((Y, pY), axis=2)\n",
    "        \n",
    "        self.x = self.x[19:]\n",
    "        self.ts = self.ts[19:]\n",
    "        self.codedtime = self.codedtime[19:]\n",
    "\n",
    "        return self.x, Y, self.ts, self.codedtime\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.n / self.batch_size))\n",
    "\n",
    "    def __del__(self):\n",
    "        del self.x, self.y, self.indexes, self.ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pro(file):\n",
    "    fname = os.path.splitext(os.path.split(file)[-1])[0]\n",
    "    print('Processing'+fname)\n",
    "    dataset = MyDataset_p(file)\n",
    "    x, y, ts, ct = dataset()\n",
    "    \n",
    "    with h5py.File('train/' + fname+'.hdf', 'a') as new_f:\n",
    "        new_f.create_dataset('x', data=x)\n",
    "        new_f.create_dataset('y', data=y)\n",
    "        new_f.create_dataset('timestamp', data=ts)\n",
    "        new_f.create_dataset('codedtime', data=ct)\n",
    "    print('Done'+fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing20190401_20190412\n",
      "Done20190401_20190412\n"
     ]
    }
   ],
   "source": [
    "for i in range(train_f):\n",
    "    data_pro(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
