{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59821dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from train_Informer_mul import *\n",
    "\n",
    "from utils import *\n",
    "from models import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc10bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = sorted(glob.glob('../stock_price/train/*.hdf'))\n",
    "train_f.remove('../stock_price/train\\\\20190425_20190510.hdf')\n",
    "test_f = sorted(glob.glob('../stock_price/test/*.hdf'))\n",
    "# test_f.remove('../stock_price/test\\IC2003_20191018.hdf') # batch为256时，第71个batch大小为2， 不足以用于预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d80c8671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf705271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../stock_price/train\\\\20190617_20190628.hdf',\n",
       " '../stock_price/train\\\\20190628_20190710.hdf',\n",
       " '../stock_price/train\\\\20190710_20190723.hdf',\n",
       " '../stock_price/train\\\\20190723_20190731.hdf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f = train_f[-4:]\n",
    "train_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81c0c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "enc_in = 15\n",
    "dec_in = 2\n",
    "c_out = 1 \n",
    "seq_len = 20\n",
    "out_len = 13\n",
    "d_model = 16\n",
    "d_ff = 8\n",
    "n_heads = 6\n",
    "label_len = 10\n",
    "e_layers = 3\n",
    "d_layers = 2\n",
    "scaler = False\n",
    "opt_s = False\n",
    "\n",
    "decay = 1500\n",
    "dropout = 0.1\n",
    "batch_size = 256\n",
    "val_batch = 512\n",
    "lr = 0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3f415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Informer = Train_Informer_mul(enc_in, dec_in, c_out, seq_len, out_len, d_model, d_ff, n_heads, \n",
    "                                e_layers, d_layers, label_len,\n",
    "                                dropout, batch_size, val_batch, lr,\n",
    "                              device, train_f, test_f,scaler, decay, opt_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ea3023e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informer(\n",
      "  (enc_embedding): DataEmbedding(\n",
      "    (value_embedding): TokenEmbedding(\n",
      "      (tokenConv): Conv1d(15, 16, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
      "    )\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (dec_embedding): DataEmbedding(\n",
      "    (value_embedding): TokenEmbedding(\n",
      "      (tokenConv): Conv1d(2, 16, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
      "    )\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (attn_layers): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (attention): AttentionLayer(\n",
      "          (inner_attention): FullAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (out_projection): Linear(in_features=12, out_features=16, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (attention): AttentionLayer(\n",
      "          (inner_attention): FullAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (out_projection): Linear(in_features=12, out_features=16, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (attention): AttentionLayer(\n",
      "          (inner_attention): FullAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (out_projection): Linear(in_features=12, out_features=16, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): ConvLayer(\n",
      "        (downConv): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ELU(alpha=1.0)\n",
      "        (maxPool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (1): ConvLayer(\n",
      "        (downConv): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ELU(alpha=1.0)\n",
      "        (maxPool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (self_attention): AttentionLayer(\n",
      "          (inner_attention): FullAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (out_projection): Linear(in_features=12, out_features=16, bias=True)\n",
      "        )\n",
      "        (cross_attention): AttentionLayer(\n",
      "          (inner_attention): FullAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (out_projection): Linear(in_features=12, out_features=16, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (self_attention): AttentionLayer(\n",
      "          (inner_attention): FullAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (out_projection): Linear(in_features=12, out_features=16, bias=True)\n",
      "        )\n",
      "        (cross_attention): AttentionLayer(\n",
      "          (inner_attention): FullAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=12, bias=True)\n",
      "          (out_projection): Linear(in_features=12, out_features=16, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (projection): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Informer._build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f552927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Informer._selct_optim('adam')\n",
    "Informer._selct_scheduler(patience=10, factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49a0125a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate is set to 0.0001\n",
      "Warm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a26080797148a9bcad6dad77a5becb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 |Train_Loss:0.503022 |R2:-0.229342|Val_Loss:0.461641 |R2:0.004480 |Rate:0.516 |lr:0.000100\n",
      "Learning Rate is set to 0.00018\n",
      "Epoch:  2 |Train_Loss:0.422758 |R2:-0.057839|Val_Loss:0.449862 |R2:0.026769 |Rate:0.555 |lr:0.000180\n",
      "Learning Rate is set to 0.00026000000000000003\n",
      "Epoch:  3 |Train_Loss:0.400921 |R2:-0.023439|Val_Loss:0.443734 |R2:0.067144 |Rate:0.594 |lr:0.000260\n",
      "Learning Rate is set to 0.00034\n",
      "Epoch:  4 |Train_Loss:0.386362 |R2:-0.003109|Val_Loss:0.437875 |R2:0.069897 |Rate:0.597 |lr:0.000340\n",
      "Learning Rate is set to 0.00042\n",
      "Epoch:  5 |Train_Loss:0.375458 |R2:0.015125|Val_Loss:0.431940 |R2:0.086103 |Rate:0.608 |lr:0.000420\n",
      "Learning Rate is set to 0.0005\n",
      "Learning Rate is set to 0.0005\n",
      "Warm Up Done\n"
     ]
    }
   ],
   "source": [
    "Informer.lr = 0.0005\n",
    "Informer.warmup_train(0.0001, 5, f='../stock_price/train/20190723_20190731.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a8c68d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning Rate is set to 0.004\n"
     ]
    }
   ],
   "source": [
    "Informer._set_lr(0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d468a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881d8902699d43a4ae7ac6a3013d1d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save here\n",
      "Epoch:  5 |Train_Loss:0.440339 |R2:0.145772|Val_Loss:0.432515 |R2:0.171887 |Rate:0.639 |lr:0.004000\n",
      "Validation R2 increased (-inf --> 0.171887).  Saving model ...\n",
      "Save here\n",
      "Epoch:  6 |Train_Loss:0.414954 |R2:0.252557|Val_Loss:0.442100 |R2:0.158280 |Rate:0.625 |lr:0.004000\n",
      "EarlyStopping counter: 1 out of 40\n"
     ]
    }
   ],
   "source": [
    "Informer.train(epochs=100, train_all=True, f='../stock_price/train/20190723_20190731.hdf',\n",
    "             val_all=True, testfile=None, save='train',patience=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53bb00f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:optiver_kaggle]",
   "language": "python",
   "name": "conda-env-optiver_kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
