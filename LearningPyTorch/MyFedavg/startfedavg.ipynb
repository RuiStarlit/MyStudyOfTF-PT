{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"startfedavg.ipynb","provenance":[],"authorship_tag":"ABX9TyPhbWXUoM0Nfr4drPv0O4J6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cf-l6MgwZrE2","executionInfo":{"status":"ok","timestamp":1626836906084,"user_tz":-480,"elapsed":17052,"user":{"displayName":"Star Rui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKPG2e_7_4-AwM1LjTrdpysn35KKdY_g2fAV_J=s64","userId":"11674646900695699982"}},"outputId":"1f41d399-e565-4481-9c1f-a54645bbac71"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6AqYA-8asB9","executionInfo":{"status":"ok","timestamp":1626836909991,"user_tz":-480,"elapsed":1130,"user":{"displayName":"Star Rui","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKPG2e_7_4-AwM1LjTrdpysn35KKdY_g2fAV_J=s64","userId":"11674646900695699982"}},"outputId":"4798328c-c49f-4d87-8fda-85e5a64a16bd"},"source":["\n","import os\n","path=\"/content/drive/My Drive/Colab Notebooks/FedAvg/MyFedavg\"\n","os.chdir(path)\n","os.listdir(path)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['startfedavg.ipynb',\n"," 'ResNet_test1log.txt',\n"," 'ResNet_test.py',\n"," 'test_fedavg.py',\n"," 'test1.py',\n"," '__pycache__',\n"," 'fed_cifar10iid_ResNet18_10_C[0.1]_E[10]_B[50]_loss.png',\n"," 'fed_cifar10iid_ResNet18_10_C[0.1]_E[10]_B[50]_NSHARDS[100]_avg_acc.png',\n"," 'fed_cifar10iid_ResNet18_10_C[0.1]_E[10]_B[50]_NSHARDS[100]_test_acc.png',\n"," 'fed_cifar10iid_ResNet18_50_C[0.1]_E[10]_B[50]_loss.png',\n"," 'fed_cifar10iid_ResNet18_50_C[0.1]_E[10]_B[50]_NSHARDS[100]_avg_acc.png',\n"," 'fed_cifar10iid_ResNet18_50_C[0.1]_E[10]_B[50]_NSHARDS[100]_test_acc.png',\n"," 'fed_cifar10_ResNet18_50_C[0.1]_E[10]_B[50]_loss.png',\n"," 'fed_cifar10_ResNet18_50_C[0.1]_E[10]_B[50]_NSHARDS[100]_avg_acc.png',\n"," 'fed_cifar10_ResNet18_50_C[0.1]_E[10]_B[50]_NSHARDS[100]_test_acc.png',\n"," 'fed_cifar10_ResNet18_50_C[0.1]_E[5]_B[50]_loss.png',\n"," 'fed_cifar10_ResNet18_50_C[0.1]_E[5]_B[50]_NSHARDS[100]_avg_acc.png',\n"," 'fed_cifar10_ResNet18_50_C[0.1]_E[5]_B[50]_NSHARDS[100]_test_acc.png',\n"," 'fed_cifar100_ResNet18_100_C[0.1]_E[5]_B[50]_loss.png',\n"," 'fed_cifar100_ResNet18_100_C[0.1]_E[5]_B[50]_NSHARDS[100]_avg_acc.png',\n"," 'fed_cifar100_ResNet18_100_C[0.1]_E[5]_B[50]_NSHARDS[100]_test_acc.png',\n"," 'fed_cifar100iid_ResNet18_100_C[0.1]_E[5]_B[50]_loss.png',\n"," 'fed_cifar100iid_ResNet18_100_C[0.1]_E[5]_B[50]_NSHARDS[100]_avg_acc.png',\n"," 'fed_cifar100iid_ResNet18_100_C[0.1]_E[5]_B[50]_NSHARDS[100]_test_acc.png',\n"," 'cifar10_NSHARDS50_log.txt',\n"," 'output_file.txt',\n"," 'fed_cifar10_ResNet18_100_C[0.1]_E[5]_B[50]_NSHARDS[50]_test_acc.png',\n"," 'fed_cifar10_ResNet18_100_C[0.1]_E[5]_B[50]_NSHARDS[200]_avg_acc.png',\n"," 'fed_cifar10_ResNet18_100_C[0.1]_E[5]_B[50]_NSHARDS[200]_test_acc.png',\n"," 'fed_cifar10_ResNet18_100_C[0.1]_E[5]_B[50]_NSHARDS[100]_avg_acc.png',\n"," 'fed_cifar10_ResNet18_100_C[0.1]_E[5]_B[50]_NSHARDS[100]_test_acc.png',\n"," 'fed_cifar10_ResNet18_100_C[0.1]_E[5]_B[50]_loss.png',\n"," 'utils.py',\n"," 'sampling.py',\n"," 'models.py',\n"," 'fedavg.py']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"n8xl_ZhlazRr"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2hI1pM4PbyKp","outputId":"cb6be554-43bf-485e-a28f-fa68fdd19c2c"},"source":["# -*- coding:utf-8 -*-\n","\"\"\"\n","Author: RuiStarlit\n","File: fedavg\n","Project: Fedavg\n","Create Time: 2021-07-17\n","\n","\"\"\"\n","import os\n","import copy\n","import time\n","import numpy as np\n","from tqdm import tqdm\n","\n","import torch\n","\n","from utils import average_weights, LocalUpdate, get_dataset, test_inference\n","from models import ResNet18, ResBlock, CNNMnist\n","\n","\n","class Arg:\n","    def __init__(self, frac = 0.1, dataset = 'mnist_idd'):\n","        self.gpu = 0\n","        self.num_users = 100\n","        self.dataset = 'mnist_iid'\n","        self.epochs = 100\n","        self.frac = 0.2\n","        self.num_classes = 100 if self.dataset == 'cifar100' or self.dataset =='cifar100iid' else 10\n","        # self.num_classes = 10\n","        self.local_bs = 50\n","        self.local_ep = 5\n","        self.lr = 0.01  # learning rate\n","        self.optimizer = 'sgd'\n","        self.verbose = 1\n","        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","        self.model = 'ResNet18'\n","        self.n_shards = 200\n","        self.n_imgs = 300\n","\n","\n","args = Arg()\n","\n","# __main__\n","start_time = time.time()\n","# using CPU\n","# torch.cuda.set_device(0)\n","# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# device = 'cpu'\n","device = args.device\n","print('deviece:', device)\n","print('Dataset:', args.dataset)\n","# print('Model:', args.model)\n","print('The Sampling is n_shards=', args.n_shards,'n_imgs=',args.n_imgs)\n","# global_model = CNNCifar(args)\n","# if args.trainmodel == 'cifar10':\n","#     global_model = CNNCifar10(args)\n","\n","# global_model = ResNet18(ResBlock, args)\n","if args.dataset == 'mnist_iid' or args.dataset == 'mnist_noiid':\n","    global_model = CNNMnist(args)\n","else:\n","    global_model = ResNet18(ResBlock, args)\n","global_model.to(device)\n","global_model.train()\n","print(global_model)\n","global_weights = global_model.state_dict()\n","train_dataset, test_dataset, user_groups = get_dataset(args)\n","\n","# Training\n","train_loss, train_accuracy, test_accuracy = [], [],[]\n","val_acc_list, net_list = [], []\n","cv_loss, cv_acc = [], []\n","print_every = 2\n","val_loss_pre, counter = 0, 0\n","\n","for epoch in tqdm(range(args.epochs)):\n","    local_weights, local_losses = [], []\n","    print(f'\\n | Global Training Round : {epoch + 1} |\\n')\n","\n","    global_model.train()\n","    m = max(int(args.frac * args.num_users), 1)\n","    idxs_users = np.random.choice(range(args.num_users), m, replace=False)\n","\n","    for idx in idxs_users:\n","        local_model = LocalUpdate(args=args, dataset=train_dataset,\n","                                  idxs=user_groups[idx])\n","        w, loss = local_model.update_weights(\n","            model=copy.deepcopy(global_model), global_round=epoch)\n","        local_weights.append(copy.deepcopy(w))\n","        local_losses.append(copy.deepcopy(loss))\n","\n","    # update global weights\n","    global_weights = average_weights(local_weights)\n","\n","    global_model.load_state_dict(global_weights)\n","\n","    loss_avg = sum(local_losses) / len(local_losses)\n","    train_loss.append(loss_avg)\n","\n","    # Calculate avg training accuracy over all users at every epoch\n","    list_acc, list_loss = [], []\n","    global_model.eval()\n","    for c in range(args.num_users):\n","        local_model = LocalUpdate(args=args, dataset=train_dataset,\n","                                  idxs=user_groups[idx])\n","        acc, loss = local_model.inference(model=global_model)\n","        list_acc.append(acc)\n","        list_loss.append(loss)\n","    train_accuracy.append(sum(list_acc) / len(list_acc))\n","    if hasattr(torch.cuda, 'empty_cache'):\n","        torch.cuda.empty_cache()\n","\n","    # print global training loss after every 'i' rounds\n","    # if (epoch + 1) % print_every == 0:\n","    if 1:\n","        print(f' \\nAvg Training Stats after {epoch + 1} global rounds:')\n","        print(f'Training Loss : {np.mean(np.array(train_loss))}')\n","        print('Train Accuracy: {:.2f}% \\n'.format(100 * train_accuracy[-1]))\n","    test_acc, test_loss = test_inference(args, global_model, test_dataset)\n","    test_accuracy.append(test_acc)\n","    print(\"Test Accuracy: {:.2f}%\".format(100 * test_acc))\n","\n","# Test inference after completion of training\n","test_acc, test_loss = test_inference(args, global_model, test_dataset)\n","\n","print(f' \\n Results after {args.epochs} global rounds of training:')\n","print(\"|---- Avg Train Accuracy: {:.2f}%\".format(100 * train_accuracy[-1]))\n","print(\"|---- Test Accuracy: {:.2f}%\".format(100 * test_acc))\n","print('\\n Total Run Time: {0:0.4f}'.format(time.time() - start_time))\n","\n","\n","# PLOTTING (optional)\n","import matplotlib\n","matplotlib.use('Agg')\n","import matplotlib.pyplot as plt\n","\n"," # Plot Loss curve\n","plt.figure()\n","plt.title('Training Loss vs Communication rounds')\n","plt.plot(range(len(train_loss)), train_loss, color='r')\n","plt.ylabel('Training loss')\n","plt.xlabel('Communication Rounds')\n","plt.savefig('fed_{}_{}_{}_C[{}]_E[{}]_B[{}]_loss.png'.\n","            format(args.dataset, args.model, args.epochs, args.frac,\n","                     args.local_ep, args.local_bs))\n","\n","# Plot Average Accuracy vs Communication rounds\n","plt.figure()\n","plt.title('Average Accuracy vs Communication rounds')\n","plt.plot(range(len(train_accuracy)), train_accuracy, color='k')\n","plt.ylabel('Average Accuracy')\n","plt.xlabel('Communication Rounds')\n","plt.savefig('fed_{}_{}_{}_C[{}]_E[{}]_B[{}]_NSHARDS[{}]_avg_acc.png'.\n","            format(args.dataset, args.model, args.epochs, args.frac,\n","                     args.local_ep, args.local_bs, args.n_shards))\n","plt.figure()\n","plt.title('Test Accuracy vs Communication rounds')\n","plt.plot(range(len(test_accuracy)), test_accuracy, color='k')\n","plt.ylabel('Test Accuracy')\n","plt.xlabel('Communication Rounds')\n","plt.savefig('fed_{}_{}_{}_C[{}]_E[{}]_B[{}]_NSHARDS[{}]_test_acc.png'.\n","            format(args.dataset, args.model, args.epochs, args.frac,\n","                     args.local_ep, args.local_bs, args.n_shards))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["| Global Round : 0 | Local Epoch : 2 | [0/480 (0%)]\tLoss: 0.620411\n"],"name":"stdout"}]}]}