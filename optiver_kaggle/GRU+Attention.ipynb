{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# import tensorflow.keras.backend as K\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# from tensorflow.keras.layers import Dense, Lambda, Dot, Activation, Concatenate\n",
    "# from tensorflow.keras.layers import Layer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import psutil\n",
    "psutil.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NTHREADS = psutil.cpu_count()-2\n",
    "SEED = 42\n",
    "TRAIN_BATCH_SIZE = 256\n",
    "TEST_BATCH_SIZE = 256\n",
    "BUCKET_WINDOWS2 = [(0, 100), (100, 200), (200, 300), (300, 400), (400, 500), (500, 600)]\n",
    "\n",
    "DATA_PATH = 'input/optiver-realized-volatility-prediction'\n",
    "BOOK_TRAIN_PATH = 'input/optiver-realized-volatility-prediction/book_train.parquet'\n",
    "TRADE_TRAIN_PATH = 'input/optiver-realized-volatility-prediction/trade_train.parquet'\n",
    "BOOK_TEST_PATH = 'input/optiver-realized-volatility-prediction/book_test.parquet'\n",
    "TRADE_TEST_PATH = 'input/optiver-realized-volatility-prediction/trade_test.parquet'\n",
    "CHECKPOINT = 'model_checkpoint/model_01'\n",
    "\n",
    "book_skip_columns = trade_skip_columns = ['time_id', 'row_id', 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_input = open('LSTMtemp/np_train.pkl','rb')\n",
    "np_train = pickle.load(data_input)\n",
    "data_input.close()\n",
    "\n",
    "data_input = open('LSTMtemp/targets.pkl','rb')\n",
    "targets = pickle.load(data_input)\n",
    "data_input.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(np_train.shape[0])\n",
    "train_idx, valid_idx = train_test_split(idx, shuffle=False, test_size=0.1, random_state=2021)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaler\n",
    "transformers = []\n",
    "for i in tqdm(range(np_train.shape[1])):\n",
    "    a = np.nan_to_num(np_train[train_idx, i, :])\n",
    "    b = np.nan_to_num(np_train[valid_idx, i, :])\n",
    "\n",
    "    transformer = StandardScaler() # StandardScaler is very useful!\n",
    "    np_train[train_idx, i, :] = transformer.fit_transform(a)\n",
    "    np_train[valid_idx, i, :] = transformer.transform(b)\n",
    "    transformers.append(transformer) # Save Scalers for the inference stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np_train = np.nan_to_num(np_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pickle\n",
    "data_output = open('LSTMtemp/np_train.pkl','wb')\n",
    "pickle.dump(np_train,data_output)\n",
    "data_output.close()\n",
    "\n",
    "data_output = open('LSTMtemp/targets.pkl','wb')\n",
    "pickle.dump(targets,data_output)\n",
    "data_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def rmspe(y_true, y_pred):\n",
    "    return torch.sqrt(torch.mean(torch.square((y_true - y_pred) / y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ds, y):\n",
    "        super().__init__()\n",
    "        self.ds = ds\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.ds.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.ds[idx]\n",
    "        y = self.y[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGRU(nn.Module):\n",
    "    def __init__(self,hidden_size, n_layers=1, dim_f=29):\n",
    "        super(MyGRU, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dim_f = dim_f\n",
    "#         self.w_omega = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "#         self.u_omega = nn.Parameter(torch.Tensor(hidden_size, 1))\n",
    "#         nn.init.uniform_(self.w_omega, -0.01, 0.01)\n",
    "#         nn.init.uniform_(self.u_omega, -0.01, 0.01)\n",
    "        \n",
    "        self.lstm = nn.GRU(input_size = dim_f,\n",
    "                    hidden_size = hidden_size,\n",
    "                    num_layers = n_layers\n",
    "                   )\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(hidden_size*1, 1)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc2 = nn.Linear(512,1)\n",
    "        \n",
    "        \n",
    "    def attention(self, x):\n",
    "        u = torch.tanh(torch.matmul(x, self.w_omega))\n",
    "        attn = torch.matmul(u, self.u_omega)\n",
    "        attn_score = F.softmax(attn, dim =1)\n",
    "        scored_x = x * attn_score\n",
    "        context = torch.sum(scored_x ,dim=1)\n",
    "        return context\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x.transpose_(1, 0)\n",
    "        x, h_n = self.lstm(x)\n",
    "        x = h_n.permute(1, 0 ,2)\n",
    "#         attn_output = self.attn(x)\n",
    "        x = self.flat(x)\n",
    "#         x = torch.cat((attn_output,x),1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Myloss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Myloss, self).__init__()\n",
    "    \n",
    "    def forward(self, y_true, y_pred):\n",
    "        x = torch.sqrt(torch.mean(torch.square((y_true - y_pred) / y_true)))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyGRU(\n",
      "  (lstm): GRU(29, 50)\n",
      "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "Batch_size = 1024 * 5\n",
    "train_dataset = MyDataset(np_train[train_idx, :, :], targets[train_idx])\n",
    "test_dataset = MyDataset(np_train[valid_idx, :, :], targets[valid_idx])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = Batch_size,num_workers = 0)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = Batch_size,num_workers = 0)\n",
    "\n",
    "assert torch.cuda.is_available()\n",
    "device = 'cuda'\n",
    "\n",
    "hidden_size = 50\n",
    "n_layers =1\n",
    "lr = 0.006\n",
    "\n",
    "model = MyGRU(hidden_size=hidden_size, n_layers=n_layers)\n",
    "model.to(device)\n",
    "\n",
    "criterion = Myloss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = lr)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.0000e+00,  7.3730e-01,  8.6279e-01, ..., -1.4612e-01,\n",
       "          9.0186e-01, -5.5939e-02],\n",
       "        [ 4.1870e-02,  8.6182e-01,  9.1992e-01, ..., -5.5756e-02,\n",
       "          2.5742e-02, -2.9297e-01],\n",
       "        [-3.5840e-01,  8.3740e-01,  9.2725e-01, ...,  3.3667e-01,\n",
       "          1.4131e+00, -1.2018e-01],\n",
       "        ...,\n",
       "        [-6.8164e-01,  5.0195e-01,  4.6118e-01, ..., -3.2990e-02,\n",
       "          4.1821e-01,  6.1328e-01],\n",
       "        [-7.2900e-01,  6.0254e-01,  6.6406e-01, ..., -1.0724e-01,\n",
       "          2.1069e-01, -1.8787e-01],\n",
       "        [-5.5713e-01, -5.4834e-01, -5.4639e-01, ..., -3.1836e-01,\n",
       "         -1.8835e-01, -4.4360e-01]],\n",
       "\n",
       "       [[ 0.0000e+00,  2.3792e-01,  1.7444e-01, ..., -1.4612e-01,\n",
       "          5.2051e-01, -6.0211e-02],\n",
       "        [-8.3359e+00, -3.5205e-01, -4.0942e-01, ..., -4.7900e-01,\n",
       "         -3.3105e-01, -3.5474e-01],\n",
       "        [-1.7373e+00, -4.9133e-02, -1.3098e-01, ..., -9.8828e-01,\n",
       "          2.3840e-01, -1.7712e-01],\n",
       "        ...,\n",
       "        [-6.8164e-01, -5.9863e-01, -3.7061e-01, ..., -3.2959e-02,\n",
       "         -8.3008e-01, -1.6289e+00],\n",
       "        [-3.9258e-01,  6.0272e-02,  1.2103e-01, ..., -8.1299e-01,\n",
       "          2.0520e-01, -1.6492e-01],\n",
       "        [-1.0889e+00, -1.0859e+00, -1.0869e+00, ..., -4.3335e-01,\n",
       "          3.8916e-01, -4.6509e-01]],\n",
       "\n",
       "       [[ 0.0000e+00,  2.3792e-01,  1.7444e-01, ..., -1.4612e-01,\n",
       "         -1.8994e-01, -5.8807e-02],\n",
       "        [ 4.0625e-01, -3.5205e-01, -7.7026e-02, ..., -3.9429e-01,\n",
       "         -9.0381e-01, -3.4985e-01],\n",
       "        [-4.6948e-01, -4.9133e-02,  2.2168e-01, ..., -5.4248e-01,\n",
       "         -1.6621e+00, -1.5466e-01],\n",
       "        ...,\n",
       "        [-6.8115e-01, -1.3245e-01, -4.5874e-01, ..., -3.3081e-02,\n",
       "          4.1821e-01, -1.6289e+00],\n",
       "        [-1.7393e+00, -3.0103e-01, -3.3130e-01, ...,  1.2793e-01,\n",
       "         -4.6289e-01, -9.1248e-03],\n",
       "        [-1.8281e+00, -1.8301e+00, -1.8301e+00, ..., -4.3335e-01,\n",
       "         -4.1431e-01, -4.5264e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.0000e+00,  4.0430e-01,  5.1904e-01, ...,  2.1465e+00,\n",
       "          9.0186e-01,  8.6121e-02],\n",
       "        [ 4.0625e-01,  1.6833e-01, -7.7026e-02, ..., -3.9429e-01,\n",
       "         -9.0381e-01, -3.5620e-01],\n",
       "        [ 1.1680e+00,  1.2817e-01,  2.2168e-01, ...,  6.5613e-02,\n",
       "          5.1880e-03, -1.3281e-01],\n",
       "        ...,\n",
       "        [-6.8164e-01, -8.7012e-01, -3.9160e-01, ..., -3.2623e-02,\n",
       "          9.3555e-01, -1.6299e+00],\n",
       "        [ 7.8613e-02,  2.4109e-01,  3.0200e-01, ...,  3.6304e-01,\n",
       "          9.3848e-01, -1.3721e-01],\n",
       "        [-2.2729e-01, -2.1826e-01, -2.1887e-01, ..., -5.0049e-01,\n",
       "          3.1714e-01, -5.1221e-01]],\n",
       "\n",
       "       [[ 0.0000e+00,  7.3730e-01,  5.1904e-01, ..., -1.4612e-01,\n",
       "          1.5125e-01, -6.0211e-02],\n",
       "        [ 4.1870e-02,  5.1514e-01,  2.5537e-01, ..., -2.2498e-01,\n",
       "          3.4595e-01, -2.7271e-01],\n",
       "        [-4.5483e-01,  4.8291e-01,  5.7471e-01, ..., -3.3984e-01,\n",
       "          3.3179e-01, -1.3135e-01],\n",
       "        ...,\n",
       "        [-6.8164e-01, -6.6602e-01, -4.1309e-01, ..., -3.2654e-02,\n",
       "         -8.3008e-01,  6.1328e-01],\n",
       "        [-4.5996e-01,  2.4109e-01,  3.0200e-01, ..., -3.4229e-01,\n",
       "         -3.5010e-01, -1.0394e-01],\n",
       "        [ 1.8774e-01,  1.9568e-01,  1.9507e-01, ..., -2.0325e-01,\n",
       "         -1.1250e+00, -3.8232e-01]],\n",
       "\n",
       "       [[ 0.0000e+00,  4.0430e-01,  1.7444e-01, ..., -1.4612e-01,\n",
       "          7.0703e-01, -6.0211e-02],\n",
       "        [ 4.0625e-01, -1.7859e-01, -7.7026e-02, ..., -2.6733e-01,\n",
       "         -8.4131e-01, -3.0200e-01],\n",
       "        [-6.9922e-01,  1.2817e-01,  2.2168e-01, ..., -3.3984e-01,\n",
       "         -1.3013e-01, -1.3171e-01],\n",
       "        ...,\n",
       "        [-6.8164e-01, -5.4053e-01, -8.6475e-01, ..., -3.2074e-02,\n",
       "         -8.3008e-01, -1.6299e+00],\n",
       "        [ 2.6367e+00, -3.0090e-02, -5.9845e-02, ..., -3.4229e-01,\n",
       "         -6.5967e-01, -6.1981e-02],\n",
       "        [-1.2617e+00, -1.2920e+00, -1.2930e+00, ..., -3.8550e-01,\n",
       "         -4.9146e-01, -4.5288e-01]]], dtype=float16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hyperparameter:\n",
      "      Hidden_size = 50\n",
      "      n_layers = 1\n",
      "      Learnning rate = 0.006\n",
      "      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eda031521534ba785da4ba800691177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1   |Train_Loss: 20.615730 |Val_Loss: 7.923088\n",
      "Epoch:  2   |Train_Loss: 11.317620 |Val_Loss: 4.230502\n",
      "Epoch:  3   |Train_Loss: 2.189142 |Val_Loss: 2.341012\n",
      "Epoch:  4   |Train_Loss: 1.786664 |Val_Loss: 1.539948\n",
      "Epoch:  5   |Train_Loss: 1.147261 |Val_Loss: 1.291233\n",
      "Epoch:  6   |Train_Loss: 1.316142 |Val_Loss: 1.690530\n",
      "Epoch:  7   |Train_Loss: 1.483370 |Val_Loss: 1.057308\n",
      "Epoch:  8   |Train_Loss: 0.949667 |Val_Loss: 0.640409\n",
      "Epoch:  9   |Train_Loss: 1.526880 |Val_Loss: 1.033922\n",
      "Epoch:  10   |Train_Loss: 1.594140 |Val_Loss: 0.973621\n",
      "Epoch:  11   |Train_Loss: 0.799504 |Val_Loss: 0.655258\n",
      "Epoch:  12   |Train_Loss: 1.398846 |Val_Loss: 0.854176\n",
      "Epoch:  13   |Train_Loss: 1.013826 |Val_Loss: 0.594949\n",
      "Epoch:  14   |Train_Loss: 0.651893 |Val_Loss: 0.599415\n",
      "Epoch:  15   |Train_Loss: 0.924562 |Val_Loss: 0.607906\n",
      "Epoch:  16   |Train_Loss: 0.750206 |Val_Loss: 0.692359\n",
      "Epoch:  17   |Train_Loss: 0.847324 |Val_Loss: 0.635631\n",
      "Epoch:  18   |Train_Loss: 0.956724 |Val_Loss: 0.703129\n",
      "Epoch:  19   |Train_Loss: 0.865213 |Val_Loss: 0.697114\n",
      "Epoch:  20   |Train_Loss: 0.828437 |Val_Loss: 0.599483\n",
      "连续9个epoch没有下降了\n",
      "Epoch:  21   |Train_Loss: 0.922542 |Val_Loss: 0.807639\n",
      "Epoch:  22   |Train_Loss: 0.750391 |Val_Loss: 0.591999\n",
      "Epoch:  23   |Train_Loss: 0.659795 |Val_Loss: 0.709848\n",
      "Epoch:  24   |Train_Loss: 0.897123 |Val_Loss: 0.582989\n",
      "Epoch:  25   |Train_Loss: 0.983830 |Val_Loss: 0.622448\n",
      "Epoch:  26   |Train_Loss: 1.025333 |Val_Loss: 1.000130\n",
      "Epoch:  27   |Train_Loss: 1.239485 |Val_Loss: 0.571764\n",
      "Epoch:  28   |Train_Loss: 1.245760 |Val_Loss: 1.183701\n",
      "Epoch:  29   |Train_Loss: 1.080028 |Val_Loss: 0.561413\n",
      "Epoch:  30   |Train_Loss: 1.035431 |Val_Loss: 0.644363\n",
      "Epoch:  31   |Train_Loss: 0.813408 |Val_Loss: 0.755235\n",
      "Epoch:  32   |Train_Loss: 1.450552 |Val_Loss: 1.142688\n",
      "Epoch:  33   |Train_Loss: 1.658684 |Val_Loss: 0.883151\n",
      "Epoch:  34   |Train_Loss: 0.792530 |Val_Loss: 0.982022\n",
      "Epoch:  35   |Train_Loss: 1.038808 |Val_Loss: 0.659874\n",
      "Epoch:  36   |Train_Loss: 0.929773 |Val_Loss: 1.199479\n",
      "连续9个epoch没有下降了\n",
      "Epoch:  37   |Train_Loss: 1.051060 |Val_Loss: 0.592123\n",
      "连续10个epoch没有下降了\n",
      "Epoch:  38   |Train_Loss: 1.000237 |Val_Loss: 0.685681\n",
      "连续11个epoch没有下降了\n",
      "Epoch:  39   |Train_Loss: 0.841623 |Val_Loss: 0.571915\n",
      "连续12个epoch没有下降了\n",
      "Epoch:  40   |Train_Loss: 0.749424 |Val_Loss: 0.738373\n",
      "Epoch:  41   |Train_Loss: 0.781307 |Val_Loss: 0.560080\n",
      "Epoch:  42   |Train_Loss: 0.832993 |Val_Loss: 0.550127\n",
      "Epoch:  43   |Train_Loss: 0.973893 |Val_Loss: 0.582442\n",
      "Epoch:  44   |Train_Loss: 0.688351 |Val_Loss: 0.567055\n",
      "Epoch:  45   |Train_Loss: 0.851330 |Val_Loss: 0.578516\n",
      "Epoch:  46   |Train_Loss: 0.757410 |Val_Loss: 0.580800\n",
      "Epoch:  47   |Train_Loss: 1.089938 |Val_Loss: 1.245948\n",
      "Epoch:  48   |Train_Loss: 1.190396 |Val_Loss: 1.064542\n",
      "Epoch:  49   |Train_Loss: 1.097193 |Val_Loss: 0.535084\n",
      "Epoch:  50   |Train_Loss: 0.863455 |Val_Loss: 0.831251\n",
      "Epoch:  51   |Train_Loss: 1.207298 |Val_Loss: 0.749078\n",
      "Epoch:  52   |Train_Loss: 0.884924 |Val_Loss: 1.259156\n",
      "Epoch:  53   |Train_Loss: 0.910132 |Val_Loss: 0.632547\n",
      "Epoch:  54   |Train_Loss: 0.792981 |Val_Loss: 0.668408\n",
      "Epoch:  55   |Train_Loss: 1.016806 |Val_Loss: 0.754622\n",
      "Epoch:  56   |Train_Loss: 0.922774 |Val_Loss: 1.211495\n",
      "连续9个epoch没有下降了\n",
      "Epoch:  57   |Train_Loss: 1.136965 |Val_Loss: 0.642878\n",
      "连续10个epoch没有下降了\n",
      "Epoch:  58   |Train_Loss: 1.263093 |Val_Loss: 1.398025\n",
      "连续11个epoch没有下降了\n",
      "Epoch:  59   |Train_Loss: 1.282908 |Val_Loss: 0.999445\n",
      "连续12个epoch没有下降了\n",
      "Epoch:  60   |Train_Loss: 0.870477 |Val_Loss: 0.609532\n",
      "连续13个epoch没有下降了\n",
      "Epoch:  61   |Train_Loss: 0.801333 |Val_Loss: 0.679804\n",
      "连续14个epoch没有下降了\n",
      "Epoch:  62   |Train_Loss: 0.721536 |Val_Loss: 0.858916\n",
      "连续15个epoch没有下降了\n",
      "Epoch:  63   |Train_Loss: 0.704335 |Val_Loss: 0.617697\n",
      "连续16个epoch没有下降了\n",
      "Epoch:  64   |Train_Loss: 0.621484 |Val_Loss: 0.582521\n",
      "连续17个epoch没有下降了\n",
      "Epoch:  65   |Train_Loss: 0.592480 |Val_Loss: 0.691984\n",
      "连续18个epoch没有下降了\n",
      "Epoch:  66   |Train_Loss: 0.721377 |Val_Loss: 0.724728\n",
      "连续19个epoch没有下降了\n",
      "Epoch:  67   |Train_Loss: 0.722414 |Val_Loss: 0.610481\n",
      "连续20个epoch没有下降了\n",
      "Epoch:  68   |Train_Loss: 0.814635 |Val_Loss: 0.601784\n",
      "连续21个epoch没有下降了\n",
      "Epoch:  69   |Train_Loss: 0.937673 |Val_Loss: 0.835267\n",
      "连续22个epoch没有下降了\n",
      "Epoch:  70   |Train_Loss: 0.958265 |Val_Loss: 0.561464\n",
      "连续23个epoch没有下降了\n",
      "Epoch:  71   |Train_Loss: 0.616163 |Val_Loss: 1.017016\n",
      "连续24个epoch没有下降了\n",
      "Epoch:  72   |Train_Loss: 0.948986 |Val_Loss: 1.275281\n",
      "连续25个epoch没有下降了\n",
      "Epoch:  73   |Train_Loss: 0.864672 |Val_Loss: 0.936179\n",
      "连续26个epoch没有下降了\n",
      "Epoch:  74   |Train_Loss: 0.737407 |Val_Loss: 0.688901\n",
      "连续27个epoch没有下降了\n",
      "Epoch:  75   |Train_Loss: 0.800012 |Val_Loss: 0.750423\n",
      "连续28个epoch没有下降了\n",
      "Epoch:  76   |Train_Loss: 0.896555 |Val_Loss: 0.553761\n",
      "连续29个epoch没有下降了\n",
      "Epoch:  77   |Train_Loss: 0.787144 |Val_Loss: 0.633276\n",
      "连续30个epoch没有下降了\n",
      "Epoch:  78   |Train_Loss: 0.638692 |Val_Loss: 0.728192\n",
      "连续31个epoch没有下降了\n",
      "Epoch:  79   |Train_Loss: 0.706840 |Val_Loss: 0.598232\n",
      "连续32个epoch没有下降了\n",
      "Epoch:  80   |Train_Loss: 0.649224 |Val_Loss: 0.573938\n",
      "连续33个epoch没有下降了\n",
      "Epoch:  81   |Train_Loss: 0.637604 |Val_Loss: 0.623462\n",
      "连续34个epoch没有下降了\n",
      "Epoch:  82   |Train_Loss: 0.809397 |Val_Loss: 0.697339\n",
      "连续35个epoch没有下降了\n",
      "Epoch:  83   |Train_Loss: 0.629451 |Val_Loss: 0.947031\n",
      "连续36个epoch没有下降了\n",
      "Epoch:  84   |Train_Loss: 0.796662 |Val_Loss: 0.653803\n",
      "连续37个epoch没有下降了\n",
      "Epoch:  85   |Train_Loss: 0.801539 |Val_Loss: 0.643274\n",
      "连续38个epoch没有下降了\n",
      "Epoch:  86   |Train_Loss: 0.660937 |Val_Loss: 0.655204\n",
      "连续39个epoch没有下降了\n",
      "Epoch:  87   |Train_Loss: 0.662453 |Val_Loss: 0.711425\n",
      "连续40个epoch没有下降了\n",
      "Epoch:  88   |Train_Loss: 0.811336 |Val_Loss: 0.624266\n",
      "连续41个epoch没有下降了\n",
      "Epoch:  89   |Train_Loss: 1.340089 |Val_Loss: 0.815155\n",
      "连续42个epoch没有下降了\n",
      "Epoch:  90   |Train_Loss: 1.084441 |Val_Loss: 0.738402\n",
      "连续43个epoch没有下降了\n",
      "Epoch:  91   |Train_Loss: 0.918002 |Val_Loss: 0.767763\n",
      "连续44个epoch没有下降了\n",
      "Epoch:  92   |Train_Loss: 0.731064 |Val_Loss: 0.624812\n",
      "连续45个epoch没有下降了\n",
      "Epoch:  93   |Train_Loss: 0.667901 |Val_Loss: 1.310201\n",
      "连续46个epoch没有下降了\n",
      "Epoch:  94   |Train_Loss: 0.815774 |Val_Loss: 0.579064\n",
      "连续47个epoch没有下降了\n",
      "Epoch:  95   |Train_Loss: 0.675474 |Val_Loss: 0.554703\n",
      "连续48个epoch没有下降了\n",
      "Epoch:  96   |Train_Loss: 0.659172 |Val_Loss: 0.836877\n",
      "连续49个epoch没有下降了\n",
      "Epoch:  97   |Train_Loss: 0.812618 |Val_Loss: 0.653544\n",
      "连续50个epoch没有下降了\n",
      "Epoch:  98   |Train_Loss: 0.640912 |Val_Loss: 0.969005\n",
      "连续51个epoch没有下降了\n",
      "Epoch:  99   |Train_Loss: 0.964392 |Val_Loss: 0.982931\n",
      "连续52个epoch没有下降了\n",
      "Epoch:  100   |Train_Loss: 1.219711 |Val_Loss: 0.573468\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"The Hyperparameter:\n",
    "      Hidden_size = {}\n",
    "      n_layers = {}\n",
    "      Learnning rate = {}\n",
    "      \"\"\".format(hidden_size,n_layers, lr))\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "best_loss = float('+inf')\n",
    "if hasattr(torch.cuda, 'empty_cache'):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "epochs = 100\n",
    "counter = 0\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    model.train()\n",
    "    avg_loss = []\n",
    "    for x,y in train_loader:\n",
    "        x = x.float()\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(y,output)\n",
    "        avg_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss = np.array(avg_loss).mean()\n",
    "    train_loss.append(avg_loss)\n",
    "    \n",
    "    model.eval()\n",
    "    val_aloss = []\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_loader:\n",
    "            x = x.float()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            output = model(x)\n",
    "            loss = criterion(y, output)\n",
    "            val_aloss.append(loss.item())\n",
    "        val_aloss = np.array(val_aloss).mean()\n",
    "        val_loss.append(val_aloss)\n",
    "    \n",
    "    if val_aloss <best_loss:\n",
    "        best_loss = val_aloss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), 'MyLStm_model.pt')\n",
    "        counter = 0\n",
    "    counter += 1\n",
    "    if counter >= 9:\n",
    "        print('连续{}个epoch没有下降了'.format(counter))\n",
    "    print('Epoch:  {}   |Train_Loss: {:.6f} |Val_Loss: {:.6f}'.format(epoch + 1,avg_loss,val_aloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min val_loss is: 0.2464742437005043 at 49 epoch\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "\n",
    "plt.legend(['train','test'], loc = 'upper left')\n",
    "plt.show()\n",
    "print('Min val_loss is:',best_loss,'at',best_epoch,'epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.min(history.history['val_loss'])\n",
    "print(f'The best val_loss is {a:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del np_train, np_books, np_trades\n",
    "z = gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pool = Pool(NTHREADS)\n",
    "r = pool.map(process_book_test_chunk, book_test_chunks)\n",
    "pool.close()\n",
    "\n",
    "a1, _ = zip(*r)\n",
    "np_books = [np.concatenate(a1[i], axis=0) for i in range(len(a1))]\n",
    "np_books = np.concatenate(np_books, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pool = Pool(NTHREADS)\n",
    "r = pool.map(process_trade_test_chunk, trade_test_chunks)\n",
    "pool.close()\n",
    "\n",
    "a1, _ = zip(*r)\n",
    "np_trades = [np.concatenate(a1[i], axis=0) for i in range(len(a1))]\n",
    "np_trades = np.concatenate(np_trades, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np_books.shape, np_trades.shape)\n",
    "np_test = np.concatenate((np_books, np_trades), axis=2)\n",
    "print(np_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaler\n",
    "for i in tqdm(range(np_test.shape[1])):\n",
    "    transformer = transformers[i]\n",
    "    np_test[:, i, :] = transformer.transform(np.nan_to_num(np_test[:, i, :]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_test = np.nan_to_num(np_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(checkpoint_filepath)\n",
    "res = model.predict(np_test, batch_size=TEST_BATCH_SIZE)\n",
    "res = np.clip(res, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('./model_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:optiver_kaggle]",
   "language": "python",
   "name": "conda-env-optiver_kaggle-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
