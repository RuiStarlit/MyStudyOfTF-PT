{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.058186,
     "end_time": "2021-09-20T06:16:40.384016",
     "exception": false,
     "start_time": "2021-09-20T06:16:40.325830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "https://towardsdatascience.com/stock-predictions-with-state-of-the-art-transformer-and-time-embeddings-3a4485237de6\n",
    "https://papers.nips.cc/paper/2019/file/6775a0635c302542da2c32aa19d86be0-Paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:16:40.478913Z",
     "iopub.status.busy": "2021-09-20T06:16:40.478003Z",
     "iopub.status.idle": "2021-09-20T06:16:42.012151Z",
     "shell.execute_reply": "2021-09-20T06:16:42.012886Z",
     "shell.execute_reply.started": "2021-09-20T03:42:23.231005Z"
    },
    "papermill": {
     "duration": 1.589427,
     "end_time": "2021-09-20T06:16:42.013244",
     "exception": false,
     "start_time": "2021-09-20T06:16:40.423817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "USE_TPU=False\n",
    "\n",
    "if USE_TPU:\n",
    "    !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
    "    !python pytorch-xla-env-setup.py --version nightly --apt-packages libomp5 libopenblas-dev\n",
    "\n",
    "\n",
    "    import torch_xla\n",
    "    import torch_xla.core.xla_model as xm\n",
    "    import torch_xla.distributed.parallel_loader as pl\n",
    "    import torch_xla.distributed.xla_multiprocessing as xmp   \n",
    "    import torch_xla.debug.metrics as met\n",
    "\n",
    "    \n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    device=xm.xla_device()\n",
    "    !pip install -U numpy\n",
    "else:\n",
    "    \n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    device=torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:16:42.081215Z",
     "iopub.status.busy": "2021-09-20T06:16:42.080296Z",
     "iopub.status.idle": "2021-09-20T06:16:43.060627Z",
     "shell.execute_reply": "2021-09-20T06:16:43.060018Z",
     "shell.execute_reply.started": "2021-09-20T03:42:24.568795Z"
    },
    "papermill": {
     "duration": 1.016167,
     "end_time": "2021-09-20T06:16:43.060846",
     "exception": false,
     "start_time": "2021-09-20T06:16:42.044679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:16:43.126700Z",
     "iopub.status.busy": "2021-09-20T06:16:43.125747Z",
     "iopub.status.idle": "2021-09-20T06:16:43.132703Z",
     "shell.execute_reply": "2021-09-20T06:16:43.132131Z",
     "shell.execute_reply.started": "2021-09-20T03:42:25.520386Z"
    },
    "papermill": {
     "duration": 0.042636,
     "end_time": "2021-09-20T06:16:43.132845",
     "exception": false,
     "start_time": "2021-09-20T06:16:43.090209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(s):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "    torch.cuda.manual_seed_all(s)\n",
    "    torch.cuda.manual_seed(s)\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "    \n",
    "seed_everything(2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:16:43.196074Z",
     "iopub.status.busy": "2021-09-20T06:16:43.195340Z",
     "iopub.status.idle": "2021-09-20T06:16:43.200403Z",
     "shell.execute_reply": "2021-09-20T06:16:43.199862Z",
     "shell.execute_reply.started": "2021-09-20T03:42:25.531674Z"
    },
    "papermill": {
     "duration": 0.038371,
     "end_time": "2021-09-20T06:16:43.200549",
     "exception": false,
     "start_time": "2021-09-20T06:16:43.162178",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    num_buckets= 600\n",
    "    num_features= 11\n",
    "    batch_size=128\n",
    "    epochs=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:16:43.268111Z",
     "iopub.status.busy": "2021-09-20T06:16:43.267300Z",
     "iopub.status.idle": "2021-09-20T06:18:01.598943Z",
     "shell.execute_reply": "2021-09-20T06:18:01.599483Z",
     "shell.execute_reply.started": "2021-09-20T03:42:25.538688Z"
    },
    "papermill": {
     "duration": 78.368757,
     "end_time": "2021-09-20T06:18:01.599702",
     "exception": false,
     "start_time": "2021-09-20T06:16:43.230945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/optiver-realized-volatility-prediction/train_book'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0c93b43eb637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbook_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mbook_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mbook_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-0c93b43eb637>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mall_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_book_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../input/optiver-realized-volatility-prediction/train_book\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_book_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/optiver-realized-volatility-prediction/train_book'"
     ]
    }
   ],
   "source": [
    "def get_dataset():\n",
    "    all_df=[]\n",
    "    train_book_folder = \"../input/optiver-realized-volatility-prediction/train_book\"\n",
    "    for i, stock_file in enumerate(os.listdir(train_book_folder)):\n",
    "        if i%20==0:\n",
    "            print(i)\n",
    "        file_path=os.path.join(train_book_folder, stock_file)\n",
    "        stock_df=pd.read_pickle(file_path)\n",
    "        all_df.append(stock_df)\n",
    "    \n",
    "    book_df=pd.concat(all_df)\n",
    "    return book_df\n",
    "\n",
    "book_df=get_dataset()\n",
    "book_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032134,
     "end_time": "2021-09-20T06:18:01.664285",
     "exception": false,
     "start_time": "2021-09-20T06:18:01.632151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:01.739234Z",
     "iopub.status.busy": "2021-09-20T06:18:01.738301Z",
     "iopub.status.idle": "2021-09-20T06:18:01.741729Z",
     "shell.execute_reply": "2021-09-20T06:18:01.742235Z",
     "shell.execute_reply.started": "2021-09-20T03:43:56.877251Z"
    },
    "papermill": {
     "duration": 0.045174,
     "end_time": "2021-09-20T06:18:01.742420",
     "exception": false,
     "start_time": "2021-09-20T06:18:01.697246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "window=4\n",
    "def smoothing(x):\n",
    "    if x.shape[0] < window:\n",
    "        return x\n",
    "    x=x.copy()\n",
    "    try:\n",
    "        cum_x=np.cumsum(x, axis=0)\n",
    "        x_rolling=(cum_x[window:, :] - cum_x[:-window, :])/window\n",
    "        x[window:, :]=x_rolling\n",
    "    except:\n",
    "        print('dfsf')\n",
    "        pass\n",
    "    return x\n",
    "\n",
    "def smoothing_1d(x):\n",
    "    if x.shape[0] < window:\n",
    "        return x\n",
    "    x=x.copy()\n",
    "    try:\n",
    "        cum_x=np.cumsum(x)\n",
    "        x_rolling=(cum_x[window:] - cum_x[:-window])/window\n",
    "        x[window:]=x_rolling\n",
    "    except:\n",
    "        pass\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:01.841406Z",
     "iopub.status.busy": "2021-09-20T06:18:01.827466Z",
     "iopub.status.idle": "2021-09-20T06:18:01.844677Z",
     "shell.execute_reply": "2021-09-20T06:18:01.844050Z",
     "shell.execute_reply.started": "2021-09-20T03:43:56.886523Z"
    },
    "papermill": {
     "duration": 0.069083,
     "end_time": "2021-09-20T06:18:01.844860",
     "exception": false,
     "start_time": "2021-09-20T06:18:01.775777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OptiverDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, indices, features, target):\n",
    "        self.indices=indices\n",
    "        self.target=target\n",
    "        self.features=features\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def calculate_wap(self, ask_price, bid_price, ask_size, bid_size):\n",
    "        ask_size=np.exp(ask_size) - 1\n",
    "        bid_size=np.exp(bid_size) - 1\n",
    "        wap = (ask_price * bid_size) + (bid_price * ask_size)\n",
    "        wap = wap / (ask_size + bid_size)\n",
    "        return wap\n",
    "    \n",
    "    def get_log_returns(self, wap):\n",
    "        s=np.diff(np.log(wap))\n",
    "        s[s==-np.inf]=0.0\n",
    "        return s\n",
    "    \n",
    "    def get_realized_volatility(self, s):\n",
    "        rv=np.sqrt(np.sum( (s**2) ))\n",
    "        return rv\n",
    "    \n",
    "    def get_features(self, feat):\n",
    "        bid_price1=feat[:, 0]\n",
    "        ask_price1=feat[:, 1]\n",
    "        bid_price2= feat[:, 2]\n",
    "        ask_price2= feat[:, 3]\n",
    "        bid_size1=feat[:, 4]\n",
    "        ask_size1=feat[:, 5]\n",
    "        bid_size2=feat[:, 6]\n",
    "        ask_size2=feat[:, 7]\n",
    "        \n",
    "        wap1=self.calculate_wap(ask_price1, bid_price1, ask_size1, bid_size1)\n",
    "        wap2=self.calculate_wap(ask_price2, bid_price2, ask_size2, bid_size2)\n",
    "        \n",
    "        s1=self.get_log_returns(wap1)\n",
    "        s2=self.get_log_returns(wap2)\n",
    "        \n",
    "        rv1=self.get_realized_volatility(s1)\n",
    "        rv2=self.get_realized_volatility(s2)\n",
    "        \n",
    "        if rv1==0:\n",
    "            rv1=rv2\n",
    "        elif rv2==0:\n",
    "            rv2=rv1\n",
    "        \n",
    "        return (wap1,wap2, s1, s2, rv1, rv2)\n",
    "    \n",
    "    def get_binary_target_features(self, y_target, rv1, rv2):\n",
    "        y_binary1=(y_target>rv1)\n",
    "        y_binary2=(y_target>rv2)\n",
    "        \n",
    "        weights1=np.abs(y_target - rv1) + 1e-10\n",
    "        weights2=np.abs(y_target - rv2) + 1e-10\n",
    "        \n",
    "        return (y_binary1, y_binary2, weights1, weights2)\n",
    "        \n",
    "    \n",
    "    def get_price_differences(self, feat, seq_len):\n",
    "        bid_price1=feat[:, 0]\n",
    "        ask_price1=feat[:, 1]\n",
    "        bid_price2= feat[:, 2]\n",
    "        ask_price2= feat[:, 3]\n",
    "        \n",
    "        price_diff1 = bid_price1 - ask_price1\n",
    "        price_diff2 = bid_price2 - ask_price2\n",
    "        \n",
    "        ask_diff = ask_price1 - ask_price2\n",
    "        bid_diff = bid_price1 - bid_price2\n",
    "        \n",
    "        price_diff=np.zeros((4, 600) )\n",
    "        price_diff[0, -seq_len:]=price_diff1\n",
    "        price_diff[1, -seq_len:]=price_diff2\n",
    "        price_diff[2, -seq_len:]=ask_diff\n",
    "        price_diff[3, -seq_len:]=bid_diff\n",
    "        \n",
    "        price_diff=torch.tensor(price_diff, dtype=torch.float32).transpose(1, 0)\n",
    "        return price_diff\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i=self.indices[idx]\n",
    "        feat=np.array(self.features[i])\n",
    "        y_target=self.target[i]\n",
    "        (seq_len, num_features) = (feat.shape[0], feat.shape[1])\n",
    "        \n",
    "        (wap1_arr,wap2_arr, s1_arr, s2_arr, rv1, rv2)=self.get_features(feat)\n",
    "        price_diff = self.get_price_differences(feat, seq_len)\n",
    "        ratio=y_target/rv1\n",
    "        if ratio >=2.23:#99.95 percent ratio - 2.23\n",
    "            ratio=2.23+np.log(1 + ratio - 2.23)\n",
    "        \n",
    "        y_target=ratio * rv1\n",
    "        (y_binary1, y_binary2, weight1, weight2)=self.get_binary_target_features(y_target, rv1, rv2)\n",
    "        \n",
    "        feat=smoothing(feat)\n",
    "        wap1_arr=smoothing_1d(wap1_arr)\n",
    "        wap2_arr=smoothing_1d(wap2_arr)\n",
    "        \n",
    "        X=torch.zeros(600, num_features)\n",
    "        \n",
    "        mask=np.zeros(600)\n",
    "        mask[-seq_len:]=1\n",
    "        \n",
    "        wap1=torch.zeros(600)\n",
    "        wap2=torch.zeros(600)\n",
    "        s1=torch.zeros(600)\n",
    "        s2=torch.zeros(600)\n",
    "        \n",
    "        mask=torch.tensor(mask, dtype=torch.long)\n",
    "        X[-seq_len:]=torch.tensor(feat, dtype=torch.float32)\n",
    "        wap1[-seq_len:]=torch.tensor(wap1_arr, dtype=torch.float32)\n",
    "        wap2[-seq_len:]=torch.tensor(wap2_arr, dtype=torch.float32)\n",
    "        \n",
    "        s1[-seq_len+1:]=torch.tensor(s1_arr, dtype=torch.float32)\n",
    "        s2[-seq_len+1:]=torch.tensor(s2_arr, dtype=torch.float32)\n",
    "        \n",
    "        weight1=torch.tensor(weight1, dtype=torch.float32)\n",
    "        weight2=torch.tensor(weight2, dtype=torch.float32)\n",
    "        \n",
    "        rv1=torch.tensor(rv1, dtype=torch.float32)\n",
    "        rv2=torch.tensor(rv2, dtype=torch.float32)\n",
    "        \n",
    "        y_binary1=torch.tensor(y_binary1, dtype=torch.float32)\n",
    "        y_binary2=torch.tensor(y_binary2, dtype=torch.float32)\n",
    "        \n",
    "        y_target=torch.tensor(y_target, dtype=torch.float32)\n",
    "        return (X, price_diff, mask, wap1, wap2, s1, s2, rv1, rv2, weight1, weight2, y_binary1, y_binary2, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:02.031848Z",
     "iopub.status.busy": "2021-09-20T06:18:02.031013Z",
     "iopub.status.idle": "2021-09-20T06:18:02.036712Z",
     "shell.execute_reply": "2021-09-20T06:18:02.036136Z",
     "shell.execute_reply.started": "2021-09-20T03:43:56.919676Z"
    },
    "papermill": {
     "duration": 0.158543,
     "end_time": "2021-09-20T06:18:02.036891",
     "exception": false,
     "start_time": "2021-09-20T06:18:01.878348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'book_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8d1728658a10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbook_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbook_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mbook_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'book_df' is not defined"
     ]
    }
   ],
   "source": [
    "features=book_df.features.values\n",
    "target=book_df.target.values\n",
    "\n",
    "del book_df\n",
    "gc.collect()\n",
    "print(features.shape, target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:02.120303Z",
     "iopub.status.busy": "2021-09-20T06:18:02.119144Z",
     "iopub.status.idle": "2021-09-20T06:18:02.880311Z",
     "shell.execute_reply": "2021-09-20T06:18:02.880921Z",
     "shell.execute_reply.started": "2021-09-20T03:43:57.053375Z"
    },
    "papermill": {
     "duration": 0.804339,
     "end_time": "2021-09-20T06:18:02.881131",
     "exception": false,
     "start_time": "2021-09-20T06:18:02.076792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(428932,) (343145,) (85787,)\n",
      "5361 671\n"
     ]
    }
   ],
   "source": [
    "random.seed(2012)\n",
    "indices=np.arange(features.shape[0])\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_idx=indices[:int(len(indices) * 0.8)]\n",
    "valid_idx=indices[int(len(indices) * 0.8):]\n",
    "\n",
    "print(indices.shape, train_idx.shape, valid_idx.shape)\n",
    "\n",
    "train_dataset=OptiverDataset(train_idx, features, target)\n",
    "valid_dataset=OptiverDataset(valid_idx, features, target)\n",
    "\n",
    "\n",
    "train_dataloader=torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "valid_dataloader=torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=128,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(len(train_dataloader), len(valid_dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033512,
     "end_time": "2021-09-20T06:18:02.948135",
     "exception": false,
     "start_time": "2021-09-20T06:18:02.914623",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:03.030203Z",
     "iopub.status.busy": "2021-09-20T06:18:03.025158Z",
     "iopub.status.idle": "2021-09-20T06:18:03.038316Z",
     "shell.execute_reply": "2021-09-20T06:18:03.037698Z",
     "shell.execute_reply.started": "2021-09-20T03:43:57.829078Z"
    },
    "papermill": {
     "duration": 0.055732,
     "end_time": "2021-09-20T06:18:03.038476",
     "exception": false,
     "start_time": "2021-09-20T06:18:02.982744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://github.com/KrisKorrel/sparsemax-pytorch\n",
    "\n",
    "class Sparsemax(nn.Module):\n",
    "    \"\"\"Sparsemax function.\"\"\"\n",
    "\n",
    "    def __init__(self, dim=None):\n",
    "        \"\"\"Initialize sparsemax activation\n",
    "        \n",
    "        Args:\n",
    "            dim (int, optional): The dimension over which to apply the sparsemax function.\n",
    "        \"\"\"\n",
    "        super(Sparsemax, self).__init__()\n",
    "\n",
    "        self.dim = -1 if dim is None else dim\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\"Forward function.\n",
    "        Args:\n",
    "            input (torch.Tensor): Input tensor. First dimension should be the batch size\n",
    "        Returns:\n",
    "            torch.Tensor: [batch_size x number_of_logits] Output tensor\n",
    "        \"\"\"\n",
    "        # Sparsemax currently only handles 2-dim tensors,\n",
    "        # so we reshape to a convenient shape and reshape back after sparsemax\n",
    "        input = input.transpose(0, self.dim)\n",
    "        original_size = input.size()\n",
    "        input = input.reshape(input.size(0), -1)\n",
    "        input = input.transpose(0, 1)\n",
    "        dim = 1\n",
    "\n",
    "        number_of_logits = input.size(dim)\n",
    "\n",
    "        # Translate input by max for numerical stability\n",
    "        input = input - torch.max(input, dim=dim, keepdim=True)[0].expand_as(input)\n",
    "\n",
    "        # Sort input in descending order.\n",
    "        # (NOTE: Can be replaced with linear time selection method described here:\n",
    "        # http://stanford.edu/~jduchi/projects/DuchiShSiCh08.html)\n",
    "        zs = torch.sort(input=input, dim=dim, descending=True)[0]\n",
    "        range = torch.arange(start=1, end=number_of_logits + 1, step=1, device=device, dtype=input.dtype).view(1, -1)\n",
    "        range = range.expand_as(zs)\n",
    "\n",
    "        # Determine sparsity of projection\n",
    "        bound = 1 + range * zs\n",
    "        cumulative_sum_zs = torch.cumsum(zs, dim)\n",
    "        is_gt = torch.gt(bound, cumulative_sum_zs).type(input.type())\n",
    "        k = torch.max(is_gt * range, dim, keepdim=True)[0]\n",
    "\n",
    "        # Compute threshold function\n",
    "        zs_sparse = is_gt * zs\n",
    "\n",
    "        # Compute taus\n",
    "        taus = (torch.sum(zs_sparse, dim, keepdim=True) - 1) / k\n",
    "        taus = taus.expand_as(input)\n",
    "\n",
    "        # Sparsemax\n",
    "        self.output = torch.max(torch.zeros_like(input), input - taus)\n",
    "\n",
    "        # Reshape back to original shape\n",
    "        output = self.output\n",
    "        output = output.transpose(0, 1)\n",
    "        output = output.reshape(original_size)\n",
    "        output = output.transpose(0, self.dim)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        \"\"\"Backward function.\"\"\"\n",
    "        dim = 1\n",
    "\n",
    "        nonzeros = torch.ne(self.output, 0)\n",
    "        sum = torch.sum(grad_output * nonzeros, dim=dim) / torch.sum(nonzeros, dim=dim)\n",
    "        self.grad_input = nonzeros * (grad_output - sum.expand_as(grad_output))\n",
    "\n",
    "        return self.grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:03.130851Z",
     "iopub.status.busy": "2021-09-20T06:18:03.124752Z",
     "iopub.status.idle": "2021-09-20T06:18:03.138446Z",
     "shell.execute_reply": "2021-09-20T06:18:03.137867Z",
     "shell.execute_reply.started": "2021-09-20T03:43:57.847438Z"
    },
    "papermill": {
     "duration": 0.066822,
     "end_time": "2021-09-20T06:18:03.138610",
     "exception": false,
     "start_time": "2021-09-20T06:18:03.071788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sparsemax = Sparsemax(dim=-1)\n",
    "\n",
    "def get_activation_fn(activation):\n",
    "    if activation=='gelu':\n",
    "        return nn.GELU()\n",
    "    elif activation=='relu':\n",
    "        return nn.ReLU()\n",
    "    \n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    d_k=query.size(-1)\n",
    "    scores=torch.matmul( query, key.transpose(-1, -2) )/np.sqrt(d_k)\n",
    "    #scores=torch.tril(scores)\n",
    "    if mask is not None:\n",
    "        scores=scores.masked_fill(mask == 0, -1e9)\n",
    "    \n",
    "    #p_attn=torch.softmax(scores, dim=-1)\n",
    "    p_attn=sparsemax(scores)\n",
    "    x_attn=torch.matmul(p_attn, value)\n",
    "    if dropout:\n",
    "        x_attn=dropout(x_attn)\n",
    "        \n",
    "    return p_attn, x_attn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_features, dmodel, nhead,activation,norm,dropout):\n",
    "        super().__init__()\n",
    "        self.dmodel=dmodel\n",
    "        self.nhead=nhead\n",
    "        self.d_k=dmodel//nhead #Size\n",
    "        \n",
    "        self.activation=activation\n",
    "        self.norm=norm\n",
    "        self.dropout=dropout\n",
    "        \n",
    "        #self.Q=nn.Linear(num_features, dmodel)\n",
    "        #self.K=nn.Linear(num_features, dmodel)\n",
    "        #self.V=nn.Linear(num_features, dmodel)\n",
    "        \n",
    "        self.Q=nn.Conv1d(num_features, dmodel, 5, padding=2)\n",
    "        self.K=nn.Conv1d(num_features, dmodel, 5, padding=2)\n",
    "        self.V=nn.Conv1d(num_features, dmodel, 5, padding=2)\n",
    "        \n",
    "        \n",
    "        self.W=nn.Linear(dmodel, num_features)\n",
    "        \n",
    "        #nn.init.uniform_(self.Q.weight, -1/np.sqrt(2*num_features), 1/np.sqrt(2*num_features))\n",
    "        #nn.init.uniform_(self.K.weight, -1/np.sqrt(2*num_features), 1/np.sqrt(2*num_features))\n",
    "        #nn.init.uniform_(self.V.weight, -1/np.sqrt(2*num_features), 1/np.sqrt(2*num_features))\n",
    "        #nn.init.uniform_(self.W.weight, -1/np.sqrt(2*num_features), 1/np.sqrt(2*num_features))\n",
    "        \n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        bsize=x.size(0)\n",
    "        x=self.norm(x)\n",
    "        x=x.transpose(2, 1)\n",
    "        query=self.Q(x).transpose(2, 1).view(bsize, -1, self.nhead, self.d_k)\n",
    "        key=self.K(x).transpose(2, 1).view(bsize, -1, self.nhead, self.d_k)\n",
    "        value=self.V(x).transpose(2, 1).view(bsize, -1, self.nhead, self.d_k)\n",
    "        mask=mask.unsqueeze(-1).unsqueeze(-1)\n",
    "        \n",
    "        #query=self.Q(x).view(bsize, -1, self.nhead, self.d_k)\n",
    "        #key=self.K(x).view(bsize, -1, self.nhead, self.d_k)\n",
    "        #value=self.V(x).view(bsize, -1, self.nhead, self.d_k)\n",
    "        \n",
    "        \n",
    "        p_attn, x_attn=attention(query, key, value, mask, self.dropout)\n",
    "        x_attn=x_attn.view(bsize, -1, self.nhead*self.d_k)\n",
    "        \n",
    "        x_attn=self.W(x_attn)\n",
    "        x=x.transpose(2, 1)\n",
    "        x=x+x_attn\n",
    "        return x\n",
    "\n",
    "class TimeSeriesAttentionLayer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_features=32,\n",
    "                 dmodel=128,\n",
    "                 nhead=4,\n",
    "                 dim_feed_forward=512,\n",
    "                 activation='relu', \n",
    "                 dropout=0.1\n",
    "                ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.num_features=num_features\n",
    "        self.dmodel=dmodel\n",
    "        self.nhead=nhead\n",
    "        self.dim_feed_forward=dim_feed_forward\n",
    "        self.activation=get_activation_fn('gelu')\n",
    "        self.norm=nn.LayerNorm(num_features)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "        self.multihead_attn=MultiHeadAttention(num_features,\n",
    "                                               dmodel,\n",
    "                                               nhead,\n",
    "                                               self.activation,\n",
    "                                               self.norm,\n",
    "                                               self.dropout\n",
    "                                              )\n",
    "        \n",
    "        self.conv1=nn.Conv1d(num_features, dim_feed_forward, 5, padding=2)\n",
    "        self.conv2=nn.Conv1d(dim_feed_forward, num_features, 5, padding=2)\n",
    "        #self.linear1=nn.Linear(num_features, dim_feed_forward)\n",
    "        #self.linear2=nn.Linear(dim_feed_forward, num_features)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x=self.multihead_attn(x, mask)\n",
    "        x=self.norm(x)\n",
    "        #x_ffn=self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "        x_ffn=self.conv2(self.dropout(self.activation(self.conv1(x.transpose(1, 2))))).transpose(2, 1)\n",
    "        x=x+x_ffn\n",
    "        return x\n",
    "\n",
    "\n",
    "class FeatureExtractorWith1DConv(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.pre_bn=nn.BatchNorm1d(input_size)\n",
    "        \n",
    "        #self.linear1=nn.Linear(input_size, 2*output_size)\n",
    "        #self.bn1=nn.BatchNorm1d(2*output_size)\n",
    "        \n",
    "        #self.linear2=nn.Linear(2*output_size, output_size)\n",
    "        #self.bn2=nn.BatchNorm1d(output_size)\n",
    "        \n",
    "        self.conv1=nn.Conv1d(input_size, 2*output_size, 5, padding=2)\n",
    "        self.bn1=nn.BatchNorm1d(2*output_size)\n",
    "        \n",
    "        self.conv2=nn.Conv1d(2*output_size, output_size, 5, padding=2)\n",
    "        self.bn2=nn.BatchNorm1d(output_size)\n",
    "        \n",
    "        self.activation=nn.GELU()\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=x.transpose(1, 2)\n",
    "        x=self.pre_bn(x)\n",
    "        x=self.dropout(self.activation(self.bn1(self.conv1(x))))\n",
    "        x=self.activation(self.bn2(self.conv2(x)))\n",
    "        x=x.transpose(1, 2)\n",
    "        \n",
    "        #x=self.pre_bn(x.transpose(2, 1)).transpose(2, 1)\n",
    "        #x=self.dropout(self.activation(self.bn1( self.linear1(x).transpose(2, 1) ).transpose(2, 1)))\n",
    "        #x=self.activation(self.bn2( self.linear2(x).transpose(2, 1) ).transpose(2, 1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:03.219883Z",
     "iopub.status.busy": "2021-09-20T06:18:03.217516Z",
     "iopub.status.idle": "2021-09-20T06:18:03.220761Z",
     "shell.execute_reply": "2021-09-20T06:18:03.221315Z",
     "shell.execute_reply.started": "2021-09-20T03:43:57.882569Z"
    },
    "papermill": {
     "duration": 0.049989,
     "end_time": "2021-09-20T06:18:03.221505",
     "exception": false,
     "start_time": "2021-09-20T06:18:03.171516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "    def __init__(self, sz):\n",
    "        super().__init__()\n",
    "        self.bn1=nn.BatchNorm1d(sz)\n",
    "        self.linear1=nn.Linear(sz, 2*sz)\n",
    "        \n",
    "        self.bn2=nn.BatchNorm1d(2*sz)\n",
    "        self.linear2=nn.Linear(2*sz, sz)\n",
    "        \n",
    "        \n",
    "        self.activation=nn.GELU()\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.linear1(self.dropout(self.activation(self.bn1(x))))\n",
    "        x=self.linear2(self.dropout(self.activation(self.bn2(x))))\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvHead(nn.Module):\n",
    "    def __init__(self, dmodel, pool_size):\n",
    "        super().__init__()\n",
    "        self.convs=nn.Sequential(\n",
    "            nn.Conv1d(dmodel, 2*dmodel, 7, padding=3, stride=4),\n",
    "            nn.BatchNorm1d( 2*dmodel),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.Conv1d(2*dmodel, dmodel, 5, padding=2, stride=4),\n",
    "            nn.BatchNorm1d(dmodel),\n",
    "            nn.GELU(),\n",
    "            \n",
    "            nn.AdaptiveAvgPool1d(pool_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        bsize=x.size(0)\n",
    "        x=self.convs(x.transpose(1, 2))\n",
    "        return x.view(bsize, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:03.297299Z",
     "iopub.status.busy": "2021-09-20T06:18:03.296431Z",
     "iopub.status.idle": "2021-09-20T06:18:03.301136Z",
     "shell.execute_reply": "2021-09-20T06:18:03.300413Z",
     "shell.execute_reply.started": "2021-09-20T03:43:57.897999Z"
    },
    "papermill": {
     "duration": 0.046043,
     "end_time": "2021-09-20T06:18:03.301272",
     "exception": false,
     "start_time": "2021-09-20T06:18:03.255229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLPHead(nn.Module):\n",
    "    def __init__(self, sz, num_layers):\n",
    "        super().__init__()\n",
    "        self.ffn=nn.ModuleList(\n",
    "            [FFN( sz ) for _ in range(num_layers)]\n",
    "        )\n",
    "        self.dropout=nn.Dropout(0.2)\n",
    "        self.out=nn.Linear(sz, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.dropout(x)\n",
    "        for i, _ in enumerate(self.ffn):\n",
    "            x=self.ffn[i](x)\n",
    "        y=self.out(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:03.381584Z",
     "iopub.status.busy": "2021-09-20T06:18:03.379280Z",
     "iopub.status.idle": "2021-09-20T06:18:03.382492Z",
     "shell.execute_reply": "2021-09-20T06:18:03.383069Z",
     "shell.execute_reply.started": "2021-09-20T03:43:57.913429Z"
    },
    "papermill": {
     "duration": 0.048604,
     "end_time": "2021-09-20T06:18:03.383291",
     "exception": false,
     "start_time": "2021-09-20T06:18:03.334687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=config.num_buckets):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:03.462821Z",
     "iopub.status.busy": "2021-09-20T06:18:03.460514Z",
     "iopub.status.idle": "2021-09-20T06:18:03.463869Z",
     "shell.execute_reply": "2021-09-20T06:18:03.464463Z",
     "shell.execute_reply.started": "2021-09-20T03:43:57.926136Z"
    },
    "papermill": {
     "duration": 0.047929,
     "end_time": "2021-09-20T06:18:03.464656",
     "exception": false,
     "start_time": "2021-09-20T06:18:03.416727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OptiverEncoder(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.dmodel=params['dmodel']\n",
    "        self.in_features=params['in_features']\n",
    "        self.out_features=params['out_features']\n",
    "        self.num_ffn_layers=params['num_ffn_layers']\n",
    "        self.pool_size=params['pool_size']\n",
    "        \n",
    "        \n",
    "        self.dropout=nn.Dropout(0.1)\n",
    "        self.feature_extractor=FeatureExtractorWith1DConv(self.in_features, self.out_features)\n",
    "        self.positions = PositionalEncoding(self.out_features, 0.1)        \n",
    "        self.attn_layers=nn.ModuleList([TimeSeriesAttentionLayer(num_features=self.out_features,\n",
    "                                                                 dmodel=self.dmodel,\n",
    "                                                                 nhead=params['nhead'],\n",
    "                                                                 dim_feed_forward=params['dim_feed_forward'],\n",
    "                                                                ) for _ in range(params['num_attention_layers'])])\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        batch_size=x.size(0)\n",
    "        seq_len=x.size(1)\n",
    "        x=self.positions(self.feature_extractor(x))\n",
    "        for attn_layer in self.attn_layers:\n",
    "            x=attn_layer(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:03.544846Z",
     "iopub.status.busy": "2021-09-20T06:18:03.543988Z",
     "iopub.status.idle": "2021-09-20T06:18:03.548172Z",
     "shell.execute_reply": "2021-09-20T06:18:03.547567Z",
     "shell.execute_reply.started": "2021-09-20T03:43:57.944822Z"
    },
    "papermill": {
     "duration": 0.049596,
     "end_time": "2021-09-20T06:18:03.548320",
     "exception": false,
     "start_time": "2021-09-20T06:18:03.498724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OptiverModel(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.dmodel=params['dmodel']\n",
    "        self.in_features=params['in_features']\n",
    "        self.out_features=params['out_features']\n",
    "        self.num_ffn_layers=params['num_ffn_layers']\n",
    "        self.pool_size=params['pool_size']\n",
    "        \n",
    "        self.encoder=OptiverEncoder(params)\n",
    "        \n",
    "        \n",
    "        self.alpha_model=MLPHead(2 * self.out_features , self.num_ffn_layers)\n",
    "        self.binary_model=MLPHead(2 * self.out_features, self.num_ffn_layers)\n",
    "    \n",
    "    def pooling(self, x, mask):\n",
    "        mask=mask.unsqueeze(dim=-1)\n",
    "        mean_pool=(x * mask).sum(dim=1)/mask.sum(dim=1)\n",
    "        \n",
    "        max_pool=x.masked_fill(mask == 0, -1e9)\n",
    "        max_pool=torch.max(max_pool, dim=1)[0]\n",
    "        return torch.cat([mean_pool, max_pool], dim=1)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        batch_size=x.size(0)\n",
    "        seq_len=x.size(1)\n",
    "        \n",
    "        x=self.encoder(x, mask)\n",
    "        x=self.pooling(x, mask)\n",
    "        \n",
    "        yhat_alpha=self.alpha_model(x)\n",
    "        yhat_binary=self.binary_model(x)\n",
    "        \n",
    "        return yhat_alpha, yhat_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033169,
     "end_time": "2021-09-20T06:18:03.615635",
     "exception": false,
     "start_time": "2021-09-20T06:18:03.582466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# custom losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:03.698202Z",
     "iopub.status.busy": "2021-09-20T06:18:03.695945Z",
     "iopub.status.idle": "2021-09-20T06:18:03.699059Z",
     "shell.execute_reply": "2021-09-20T06:18:03.699584Z",
     "shell.execute_reply.started": "2021-09-20T03:43:57.961978Z"
    },
    "papermill": {
     "duration": 0.05046,
     "end_time": "2021-09-20T06:18:03.699786",
     "exception": false,
     "start_time": "2021-09-20T06:18:03.649326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomLosses:\n",
    "    @staticmethod\n",
    "    def MSE(y, yhat):\n",
    "        yerr=y-yhat\n",
    "        yerr=torch.square(yerr)\n",
    "        return yerr.mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def RMSE(y, yhat):\n",
    "        err=(y-yhat)\n",
    "        return torch.sqrt( torch.mean(err**2) )\n",
    "\n",
    "    @staticmethod\n",
    "    def RMSPE(y, yhat):\n",
    "        err=(y-yhat)\n",
    "        err/=y\n",
    "        err=torch.square(err)\n",
    "        return torch.sqrt( torch.mean(err) )\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_auxilary_loss(y, yhat):\n",
    "        print(y.shape, yhat.shape)\n",
    "        y=y[:, 1:config.num_buckets].squeeze(-1)\n",
    "        yhat=yhat[:, 0: config.num_buckets-1].squeeze(-1)\n",
    "\n",
    "        #Validating only the last 20 time-steps\n",
    "        y=y[:, -20:]\n",
    "        yhat=yhat[:, -20:]\n",
    "\n",
    "        yerr=100 * (y - yhat)/y\n",
    "        yerr=torch.square(yerr).view(-1).mean()\n",
    "        yerr=torch.sqrt(yerr)\n",
    "        return yerr\n",
    "    \n",
    "    @staticmethod\n",
    "    def CrossEntropyLoss(y_binary, yhat_binary, weight):\n",
    "        yhat_binary=yhat_binary.view(-1)\n",
    "        y_binary=y_binary.view(-1)\n",
    "        weight=weight.view(-1)\n",
    "        \n",
    "        weight=weight+1e-10\n",
    "        \n",
    "        p=torch.sigmoid(yhat_binary)\n",
    "        log_p1=torch.log(p+1e-10)\n",
    "        log_p0=torch.log((1-p) + 1e-10)\n",
    "\n",
    "        loss1= (-weight * (y_binary==1) * log_p1).sum()\n",
    "        loss2= (-weight * (y_binary==0) * log_p0).sum()\n",
    "        loss=(loss1+loss2)/weight.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032714,
     "end_time": "2021-09-20T06:18:03.764976",
     "exception": false,
     "start_time": "2021-09-20T06:18:03.732262",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:03.867113Z",
     "iopub.status.busy": "2021-09-20T06:18:03.856442Z",
     "iopub.status.idle": "2021-09-20T06:18:03.896916Z",
     "shell.execute_reply": "2021-09-20T06:18:03.896308Z",
     "shell.execute_reply.started": "2021-09-20T03:44:41.655921Z"
    },
    "papermill": {
     "duration": 0.09871,
     "end_time": "2021-09-20T06:18:03.897107",
     "exception": false,
     "start_time": "2021-09-20T06:18:03.798397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self, model, val_dataloader):\n",
    "        self.model=model\n",
    "        self.dataloader=val_dataloader\n",
    "        \n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        print(\"Evaluating\")\n",
    "        yprimary_true=[]; yprimary_pred1=[]; yprimary_pred2=[]\n",
    "        for i, (X, price_diff, mask, wap1, wap2, s1, s2, rv1, rv2, weight1, weight2,\n",
    "                    y_binary1, y_binary2, y_target) in enumerate(self.dataloader):\n",
    "            X=torch.cat([X, price_diff, wap1.unsqueeze(-1), wap2.unsqueeze(-1),\n",
    "                             s1.unsqueeze(-1),s2.unsqueeze(-1)], dim=-1)\n",
    "            X=X.to(device)\n",
    "            mask=mask.to(device)\n",
    "            rv1=rv1.to(device)\n",
    "            rv2=rv2.to(device)\n",
    "            y_target=y_target.to(device)\n",
    "            \n",
    "            \n",
    "            yprimary_true+=y_target.cpu().tolist()\n",
    "            with torch.no_grad():\n",
    "                yhat_alpha, yhat_binary=self.model(X, mask)\n",
    "                yhat1 = yhat_alpha[:, 0].view(-1) * rv1\n",
    "                yhat2 = yhat_alpha[:, 1].view(-1) * rv2\n",
    "                \n",
    "                yprimary_pred1+=yhat1.view(-1).cpu().tolist()\n",
    "                yprimary_pred2+=yhat2.view(-1).cpu().tolist()\n",
    "            \n",
    "            del X\n",
    "            del mask\n",
    "            del wap1\n",
    "            del s1\n",
    "        \n",
    "        yprimary_true=torch.tensor(yprimary_true, dtype=torch.float32)\n",
    "        yprimary_pred1=torch.tensor(yprimary_pred1, dtype=torch.float32)\n",
    "        yprimary_pred2=torch.tensor(yprimary_pred2, dtype=torch.float32)\n",
    "        \n",
    "        rmspe_loss1=CustomLosses.RMSPE(yprimary_true, yprimary_pred1)\n",
    "        rmspe_loss2=CustomLosses.RMSPE(yprimary_true, yprimary_pred2)\n",
    "        return (rmspe_loss1.item(), rmspe_loss2.item())\n",
    "        \n",
    "class Trainer:\n",
    "    def __init__(self, model, train_dataloader, val_dataloader,\n",
    "                 optimizer, schedular=None):\n",
    "        self.best_rmse=None\n",
    "        self.best_rmspe1=None\n",
    "        self.best_rmspe2=None\n",
    "        self.evaluator=Evaluator(model, val_dataloader)\n",
    "        \n",
    "        self.train_dataloader=train_dataloader\n",
    "        self.val_dataloader=val_dataloader\n",
    "        \n",
    "        self.model=model\n",
    "        self.optimizer=optimizer\n",
    "        self.schedular=schedular\n",
    "        self.steps=0\n",
    "        self.acculation_steps=8\n",
    "        \n",
    "        self.train_loss=[]\n",
    "        self.train_alpha1=[]\n",
    "        self.train_alpha2=[]\n",
    "        self.train_binary1=[]\n",
    "        self.train_binary2=[]\n",
    "    \n",
    "    def train_ops(self, X, mask, rv1, rv2, y_target, y_binary1, y_binary2, weight1, weight2):\n",
    "        self.steps+=1\n",
    "        self.model.train()\n",
    "        X=X.to(device)\n",
    "        mask=mask.to(device)\n",
    "        weight1=weight1.to(device)\n",
    "        weight2=weight2.to(device)\n",
    "        rv1=rv1.to(device)\n",
    "        rv2=rv2.to(device)\n",
    "        y_binary1=y_binary1.to(device)\n",
    "        y_binary2=y_binary2.to(device)\n",
    "        y_target=y_target.to(device)\n",
    "\n",
    "        yhat_alpha, yhat_binary=self.model(X, mask)\n",
    "        yhat1 = yhat_alpha[:, 0].view(-1) * rv1\n",
    "        yhat2 = yhat_alpha[:, 1].view(-1) * rv2\n",
    "        \n",
    "\n",
    "        consistency_loss=torch.abs(yhat1-yhat2).mean()\n",
    "        alpha_loss1=CustomLosses.RMSPE(y_target, yhat1)\n",
    "        alpha_loss2=CustomLosses.RMSPE(y_target, yhat2)\n",
    "\n",
    "        binary_loss1=CustomLosses.CrossEntropyLoss(y_binary1, yhat_binary[:, 0], weight1)\n",
    "        binary_loss2=CustomLosses.CrossEntropyLoss(y_binary2, yhat_binary[:, 1], weight2)\n",
    "\n",
    "        loss=(alpha_loss1+alpha_loss2) +(0.5 * (binary_loss1 + binary_loss2) ) + 0.2*consistency_loss\n",
    "        loss = loss/self.acculation_steps\n",
    "        loss.backward()\n",
    "        #torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1)\n",
    "        \n",
    "        if self.steps%self.acculation_steps==0:\n",
    "            if USE_TPU:\n",
    "                xm.optimizer_step(self.optimizer)\n",
    "            else:\n",
    "                self.optimizer.step()\n",
    "            self.model.zero_grad(set_to_none=True)\n",
    "            self.schedular.step()\n",
    "        return {\n",
    "            \"loss\": loss.item(),\n",
    "            \"alpha1\":alpha_loss1.item(),\n",
    "            \"alpha2\":alpha_loss2.item(),\n",
    "            \"binary1\": binary_loss1.item(),\n",
    "            \"binary2\": binary_loss2.item(),\n",
    "            \"consistency\": consistency_loss.item()\n",
    "        }\n",
    "                \n",
    "    def train(self):\n",
    "        for e in range(config.epochs):\n",
    "            epoch_loss=0.0; \n",
    "            epoch_alpha1=0.0; epoch_alpha2=0.0\n",
    "            epoch_binary1=0.0; epoch_binary2=0.0;\n",
    "            \n",
    "            self.model.zero_grad(set_to_none=True)\n",
    "            self.model.train()\n",
    "            for i,  (X, price_diff, mask, wap1, wap2, s1, s2, rv1, rv2, weight1, weight2,\n",
    "                    y_binary1, y_binary2, y_target) in enumerate(self.train_dataloader):\n",
    "                X=torch.cat([X, price_diff, wap1.unsqueeze(-1), wap2.unsqueeze(-1),\n",
    "                             s1.unsqueeze(-1),s2.unsqueeze(-1)], dim=-1)\n",
    "                \n",
    "                losses=self.train_ops( X, mask, rv1, rv2, y_target, y_binary1, y_binary2, weight1, weight2)\n",
    "                \n",
    "                epoch_loss = ((epoch_loss*i)+(losses['loss']))/(i+1)\n",
    "                epoch_alpha1 = ((epoch_alpha1*i)+(losses['alpha1']))/(i+1)\n",
    "                epoch_alpha2 = ((epoch_alpha2*i)+(losses['alpha2']))/(i+1)\n",
    "                epoch_binary1 = ((epoch_binary1*i)+(losses['binary1']))/(i+1)\n",
    "                epoch_binary2 = ((epoch_binary2*i)+(losses['binary2']))/(i+1)\n",
    "                \n",
    "                if i%300==0:\n",
    "                    print(\"Iteration:{}|Loss:{:.3f}\".format(i, epoch_loss))\n",
    "                    print(\"Alpha1: {:.3f} | Alpha2: {:.3f}\".format(epoch_alpha1, epoch_alpha2))\n",
    "                    print(\"binary1: {:.3f} | binary2: {:.3f}\".format(epoch_binary1, epoch_binary2))\n",
    "                    print(\"Consistency:{:.4f}\".format(losses['consistency']))\n",
    "                   \n",
    "                del X\n",
    "                del mask\n",
    "                del wap1\n",
    "                del s1\n",
    "            self.train_loss.append(epoch_loss)\n",
    "            self.train_alpha1.append(epoch_alpha1)\n",
    "            self.train_alpha2.append(epoch_alpha2)\n",
    "            self.train_binary1.append(epoch_binary1)\n",
    "            self.train_binary2.append(epoch_binary2)\n",
    "            \n",
    "            eval_rmspe1, eval_rmspe2 = self.evaluator.evaluate()\n",
    "            \n",
    "            #if self.schedular:\n",
    "            #    self.schedular.step(eval_rmspe)\n",
    "            \n",
    "            if (self.best_rmspe1 is None) or (self.best_rmspe1 > eval_rmspe1):\n",
    "                self.best_rmspe1=eval_rmspe1\n",
    "                if USE_TPU:\n",
    "                    xm.save(self.model.state_dict(),'best_rmspe1.pt')\n",
    "                else:\n",
    "                    torch.save(self.model, 'best_rmspe1.pt')\n",
    "\n",
    "            if (self.best_rmspe2 is None) or (self.best_rmspe2 > eval_rmspe2):\n",
    "                self.best_rmspe2=eval_rmspe2\n",
    "                if USE_TPU:\n",
    "                    xm.save(self.model.state_dict(),'best_rmspe2.pt')\n",
    "                else:\n",
    "                    torch.save(self.model, 'best_rmspe2.pt')\n",
    "                    \n",
    "            print()\n",
    "            print()\n",
    "            print(\"***************End of Epoch{}***************\".format(e))\n",
    "            print(\"epoch:{}-LOSS:{:.4f}\".format(e, epoch_loss))\n",
    "            print(\"Alpha1: {:.3f} | Alpha2: {:.3f}\".format(epoch_alpha1, epoch_alpha2))\n",
    "            print(\"binary1: {:.3f} | binary2: {:.3f}\".format(epoch_binary1, epoch_binary2))\n",
    "                   \n",
    "            print(\"Val RMSPE1:{:.4f}|Val RMSPE2:{:.4f}\".format( eval_rmspe1, eval_rmspe2))\n",
    "            gc.collect()\n",
    "    \n",
    "    def lr_range_test(self):\n",
    "        min_lr=1e-5\n",
    "        max_lr=1e-3\n",
    "        optimizer=torch.optim.AdamW(self.model.parameters(), lr=min_lr, weight_decay=0.001)\n",
    "        scheduler=torch.optim.lr_scheduler.StepLR(optimizer, 1, 1.03)\n",
    "        \n",
    "        losses=[]; alpha_losses1=[]; alpha_losses2=[];\n",
    "        consistency_losses=[]\n",
    "        lrs=[]\n",
    "        self.model.train()\n",
    "        self.model.zero_grad(set_to_none=True)\n",
    "        for _ in range(100):\n",
    "            for i, (X, price_diff, mask, wap1, wap2, s1, s2, rv1, rv2, weight1, weight2,\n",
    "                    y_binary1, y_binary2, y_target) in enumerate(self.train_dataloader):\n",
    "                \n",
    "                X=torch.cat([X, price_diff, wap1.unsqueeze(-1), wap2.unsqueeze(-1),\n",
    "                             s1.unsqueeze(-1),s2.unsqueeze(-1)], dim=-1)\n",
    "                \n",
    "                X=X.to(device)\n",
    "                mask=mask.to(device)\n",
    "                weight1=weight1.to(device)\n",
    "                weight2=weight2.to(device)\n",
    "                rv1=rv1.to(device)\n",
    "                rv2=rv2.to(device)\n",
    "                y_binary1=y_binary1.to(device)\n",
    "                y_binary2=y_binary2.to(device)\n",
    "                y_target=y_target.to(device)\n",
    "                \n",
    "                yhat_alpha, yhat_binary=self.model(X, mask)\n",
    "                yhat1 = yhat_alpha[:, 0].view(-1) * rv1\n",
    "                yhat2 = yhat_alpha[:, 1].view(-1) * rv2\n",
    "                \n",
    "                \n",
    "                consistency_loss=torch.sqrt(((yhat1-yhat2)**2).mean())\n",
    "                alpha_loss1=CustomLosses.RMSPE(y_target, yhat1)\n",
    "                alpha_loss2=CustomLosses.RMSPE(y_target, yhat2)\n",
    "                \n",
    "                binary_loss1=CustomLosses.CrossEntropyLoss(y_binary1, yhat_binary[:, 0], weight1)\n",
    "                binary_loss2=CustomLosses.CrossEntropyLoss(y_binary2, yhat_binary[:, 1], weight2)\n",
    "                \n",
    "                loss=(alpha_loss1+alpha_loss2) +(0.5 * (binary_loss1 + binary_loss2) ) + 0.3*consistency_loss\n",
    "                \n",
    "                loss=loss/8\n",
    "                loss.backward()\n",
    "                \n",
    "                if (i+1)%8==0:\n",
    "                    if USE_TPU:\n",
    "                        xm.optimizer_step(optimizer)\n",
    "                    else:\n",
    "                        optimizer.step()\n",
    "                    self.model.zero_grad(set_to_none=True)\n",
    "                    scheduler.step()\n",
    "\n",
    "                losses.append(loss.item())\n",
    "                alpha_losses1.append(alpha_loss1.item())\n",
    "                alpha_losses2.append(alpha_loss2.item())\n",
    "                consistency_losses.append(consistency_loss.item())\n",
    "                \n",
    "                lrs.append(scheduler.get_last_lr()[0])\n",
    "                \n",
    "                del X\n",
    "                del mask\n",
    "                \n",
    "                if i%10==0:\n",
    "                    print(\"Iteration:{}|Loss:{:.3f}|LR:{}\".format(i,loss.item(), lrs[-1]))\n",
    "                    print(\"Alpha1:{:.3f}|Alpha2:{:.3f}\".format(alpha_loss1.item(), alpha_loss2.item()))\n",
    "                    print(\"Binary1:{:.3f}|Binary2:{:.3f}\".format(binary_loss1.item(), binary_loss2.item()))\n",
    "                    print(\"Consistency:{:.4f}\".format(consistency_loss.item()))\n",
    "                    print()\n",
    "                    print('----')\n",
    "                if lrs[-1] > max_lr:\n",
    "                    break\n",
    "            if lrs[-1] > max_lr:\n",
    "                break\n",
    "        return lrs, losses, alpha_losses1, alpha_losses2, consistency_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:03.970878Z",
     "iopub.status.busy": "2021-09-20T06:18:03.969972Z",
     "iopub.status.idle": "2021-09-20T06:18:09.816547Z",
     "shell.execute_reply": "2021-09-20T06:18:09.815891Z",
     "shell.execute_reply.started": "2021-09-20T03:44:41.724169Z"
    },
    "papermill": {
     "duration": 5.886424,
     "end_time": "2021-09-20T06:18:09.816767",
     "exception": false,
     "start_time": "2021-09-20T06:18:03.930343",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params={\n",
    "    'dmodel': 128,\n",
    "    'nhead':8,\n",
    "    'in_features': 16,\n",
    "    'out_features': 128,\n",
    "    'pool_size': 4, \n",
    "    'dim_feed_forward': 256,\n",
    "    'num_attention_layers': 5,\n",
    "    'num_ffn_layers': 2\n",
    "}\n",
    "model=OptiverModel(params)\n",
    "model=model.to(device)\n",
    "\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T06:18:09.899525Z",
     "iopub.status.busy": "2021-09-20T06:18:09.898715Z",
     "iopub.status.idle": "2021-09-20T13:48:49.729798Z",
     "shell.execute_reply": "2021-09-20T13:48:49.730414Z"
    },
    "papermill": {
     "duration": 27039.878802,
     "end_time": "2021-09-20T13:48:49.730657",
     "exception": false,
     "start_time": "2021-09-20T06:18:09.851855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:0|Loss:0.357\n",
      "Alpha1: 1.059 | Alpha2: 1.070\n",
      "binary1: 0.686 | binary2: 0.768\n",
      "Consistency:0.0013\n",
      "Iteration:300|Loss:0.311\n",
      "Alpha1: 0.958 | Alpha2: 0.891\n",
      "binary1: 0.669 | binary2: 0.613\n",
      "Consistency:0.0017\n",
      "Iteration:600|Loss:0.272\n",
      "Alpha1: 0.843 | Alpha2: 0.737\n",
      "binary1: 0.652 | binary2: 0.537\n",
      "Consistency:0.0014\n",
      "Iteration:900|Loss:0.241\n",
      "Alpha1: 0.729 | Alpha2: 0.637\n",
      "binary1: 0.640 | binary2: 0.478\n",
      "Consistency:0.0010\n",
      "Iteration:1200|Loss:0.220\n",
      "Alpha1: 0.648 | Alpha2: 0.584\n",
      "binary1: 0.629 | binary2: 0.432\n",
      "Consistency:0.0010\n",
      "Iteration:1500|Loss:0.206\n",
      "Alpha1: 0.593 | Alpha2: 0.546\n",
      "binary1: 0.622 | binary2: 0.395\n",
      "Consistency:0.0012\n",
      "Iteration:1800|Loss:0.195\n",
      "Alpha1: 0.554 | Alpha2: 0.517\n",
      "binary1: 0.616 | binary2: 0.365\n",
      "Consistency:0.0009\n",
      "Iteration:2100|Loss:0.188\n",
      "Alpha1: 0.527 | Alpha2: 0.498\n",
      "binary1: 0.613 | binary2: 0.340\n",
      "Consistency:0.0008\n",
      "Iteration:2400|Loss:0.181\n",
      "Alpha1: 0.505 | Alpha2: 0.481\n",
      "binary1: 0.609 | binary2: 0.320\n",
      "Consistency:0.0008\n",
      "Iteration:2700|Loss:0.176\n",
      "Alpha1: 0.486 | Alpha2: 0.466\n",
      "binary1: 0.605 | binary2: 0.302\n",
      "Consistency:0.0007\n",
      "Iteration:3000|Loss:0.171\n",
      "Alpha1: 0.471 | Alpha2: 0.454\n",
      "binary1: 0.603 | binary2: 0.287\n",
      "Consistency:0.0007\n",
      "Iteration:3300|Loss:0.167\n",
      "Alpha1: 0.458 | Alpha2: 0.443\n",
      "binary1: 0.601 | binary2: 0.275\n",
      "Consistency:0.0007\n",
      "Iteration:3600|Loss:0.164\n",
      "Alpha1: 0.446 | Alpha2: 0.434\n",
      "binary1: 0.600 | binary2: 0.264\n",
      "Consistency:0.0007\n",
      "Iteration:3900|Loss:0.161\n",
      "Alpha1: 0.437 | Alpha2: 0.425\n",
      "binary1: 0.598 | binary2: 0.255\n",
      "Consistency:0.0006\n",
      "Iteration:4200|Loss:0.159\n",
      "Alpha1: 0.428 | Alpha2: 0.418\n",
      "binary1: 0.597 | binary2: 0.247\n",
      "Consistency:0.0007\n",
      "Iteration:4500|Loss:0.156\n",
      "Alpha1: 0.420 | Alpha2: 0.411\n",
      "binary1: 0.596 | binary2: 0.240\n",
      "Consistency:0.0005\n",
      "Iteration:4800|Loss:0.154\n",
      "Alpha1: 0.413 | Alpha2: 0.404\n",
      "binary1: 0.594 | binary2: 0.233\n",
      "Consistency:0.0006\n",
      "Iteration:5100|Loss:0.152\n",
      "Alpha1: 0.407 | Alpha2: 0.399\n",
      "binary1: 0.592 | binary2: 0.228\n",
      "Consistency:0.0005\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch0***************\n",
      "epoch:0-LOSS:0.1504\n",
      "Alpha1: 0.402 | Alpha2: 0.394\n",
      "binary1: 0.591 | binary2: 0.223\n",
      "Val RMSPE1:0.3402|Val RMSPE2:0.3289\n",
      "Iteration:0|Loss:0.099\n",
      "Alpha1: 0.240 | Alpha2: 0.240\n",
      "binary1: 0.554 | binary2: 0.066\n",
      "Consistency:0.0005\n",
      "Iteration:300|Loss:0.117\n",
      "Alpha1: 0.298 | Alpha2: 0.299\n",
      "binary1: 0.557 | binary2: 0.129\n",
      "Consistency:0.0004\n",
      "Iteration:600|Loss:0.118\n",
      "Alpha1: 0.297 | Alpha2: 0.299\n",
      "binary1: 0.564 | binary2: 0.136\n",
      "Consistency:0.0005\n",
      "Iteration:900|Loss:0.118\n",
      "Alpha1: 0.294 | Alpha2: 0.297\n",
      "binary1: 0.567 | binary2: 0.135\n",
      "Consistency:0.0004\n",
      "Iteration:1200|Loss:0.118\n",
      "Alpha1: 0.293 | Alpha2: 0.295\n",
      "binary1: 0.567 | binary2: 0.137\n",
      "Consistency:0.0003\n",
      "Iteration:1500|Loss:0.117\n",
      "Alpha1: 0.293 | Alpha2: 0.295\n",
      "binary1: 0.565 | binary2: 0.134\n",
      "Consistency:0.0004\n",
      "Iteration:1800|Loss:0.117\n",
      "Alpha1: 0.291 | Alpha2: 0.293\n",
      "binary1: 0.566 | binary2: 0.134\n",
      "Consistency:0.0005\n",
      "Iteration:2100|Loss:0.117\n",
      "Alpha1: 0.291 | Alpha2: 0.293\n",
      "binary1: 0.568 | binary2: 0.134\n",
      "Consistency:0.0004\n",
      "Iteration:2400|Loss:0.116\n",
      "Alpha1: 0.290 | Alpha2: 0.292\n",
      "binary1: 0.567 | binary2: 0.133\n",
      "Consistency:0.0003\n",
      "Iteration:2700|Loss:0.116\n",
      "Alpha1: 0.290 | Alpha2: 0.291\n",
      "binary1: 0.568 | binary2: 0.134\n",
      "Consistency:0.0005\n",
      "Iteration:3000|Loss:0.116\n",
      "Alpha1: 0.288 | Alpha2: 0.291\n",
      "binary1: 0.568 | binary2: 0.133\n",
      "Consistency:0.0005\n",
      "Iteration:3300|Loss:0.116\n",
      "Alpha1: 0.288 | Alpha2: 0.290\n",
      "binary1: 0.568 | binary2: 0.133\n",
      "Consistency:0.0003\n",
      "Iteration:3600|Loss:0.116\n",
      "Alpha1: 0.287 | Alpha2: 0.289\n",
      "binary1: 0.569 | binary2: 0.133\n",
      "Consistency:0.0003\n",
      "Iteration:3900|Loss:0.116\n",
      "Alpha1: 0.286 | Alpha2: 0.288\n",
      "binary1: 0.569 | binary2: 0.133\n",
      "Consistency:0.0005\n",
      "Iteration:4200|Loss:0.116\n",
      "Alpha1: 0.286 | Alpha2: 0.288\n",
      "binary1: 0.568 | binary2: 0.133\n",
      "Consistency:0.0003\n",
      "Iteration:4500|Loss:0.115\n",
      "Alpha1: 0.285 | Alpha2: 0.288\n",
      "binary1: 0.568 | binary2: 0.133\n",
      "Consistency:0.0004\n",
      "Iteration:4800|Loss:0.115\n",
      "Alpha1: 0.285 | Alpha2: 0.288\n",
      "binary1: 0.567 | binary2: 0.133\n",
      "Consistency:0.0005\n",
      "Iteration:5100|Loss:0.115\n",
      "Alpha1: 0.284 | Alpha2: 0.287\n",
      "binary1: 0.567 | binary2: 0.133\n",
      "Consistency:0.0004\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch1***************\n",
      "epoch:1-LOSS:0.1150\n",
      "Alpha1: 0.284 | Alpha2: 0.287\n",
      "binary1: 0.567 | binary2: 0.133\n",
      "Val RMSPE1:0.3623|Val RMSPE2:0.3458\n",
      "Iteration:0|Loss:0.111\n",
      "Alpha1: 0.291 | Alpha2: 0.300\n",
      "binary1: 0.465 | binary2: 0.134\n",
      "Consistency:0.0004\n",
      "Iteration:300|Loss:0.112\n",
      "Alpha1: 0.274 | Alpha2: 0.273\n",
      "binary1: 0.563 | binary2: 0.133\n",
      "Consistency:0.0003\n",
      "Iteration:600|Loss:0.111\n",
      "Alpha1: 0.272 | Alpha2: 0.274\n",
      "binary1: 0.560 | binary2: 0.131\n",
      "Consistency:0.0003\n",
      "Iteration:900|Loss:0.112\n",
      "Alpha1: 0.273 | Alpha2: 0.277\n",
      "binary1: 0.556 | binary2: 0.128\n",
      "Consistency:0.0004\n",
      "Iteration:1200|Loss:0.112\n",
      "Alpha1: 0.274 | Alpha2: 0.277\n",
      "binary1: 0.555 | binary2: 0.127\n",
      "Consistency:0.0005\n",
      "Iteration:1500|Loss:0.112\n",
      "Alpha1: 0.274 | Alpha2: 0.277\n",
      "binary1: 0.556 | binary2: 0.128\n",
      "Consistency:0.0005\n",
      "Iteration:1800|Loss:0.112\n",
      "Alpha1: 0.273 | Alpha2: 0.277\n",
      "binary1: 0.557 | binary2: 0.128\n",
      "Consistency:0.0003\n",
      "Iteration:2100|Loss:0.112\n",
      "Alpha1: 0.274 | Alpha2: 0.278\n",
      "binary1: 0.557 | binary2: 0.129\n",
      "Consistency:0.0003\n",
      "Iteration:2400|Loss:0.112\n",
      "Alpha1: 0.274 | Alpha2: 0.279\n",
      "binary1: 0.557 | binary2: 0.129\n",
      "Consistency:0.0004\n",
      "Iteration:2700|Loss:0.112\n",
      "Alpha1: 0.273 | Alpha2: 0.279\n",
      "binary1: 0.556 | binary2: 0.129\n",
      "Consistency:0.0003\n",
      "Iteration:3000|Loss:0.112\n",
      "Alpha1: 0.273 | Alpha2: 0.278\n",
      "binary1: 0.556 | binary2: 0.129\n",
      "Consistency:0.0003\n",
      "Iteration:3300|Loss:0.112\n",
      "Alpha1: 0.273 | Alpha2: 0.278\n",
      "binary1: 0.557 | binary2: 0.129\n",
      "Consistency:0.0003\n",
      "Iteration:3600|Loss:0.112\n",
      "Alpha1: 0.272 | Alpha2: 0.278\n",
      "binary1: 0.557 | binary2: 0.130\n",
      "Consistency:0.0004\n",
      "Iteration:3900|Loss:0.111\n",
      "Alpha1: 0.272 | Alpha2: 0.277\n",
      "binary1: 0.555 | binary2: 0.129\n",
      "Consistency:0.0004\n",
      "Iteration:4200|Loss:0.111\n",
      "Alpha1: 0.272 | Alpha2: 0.277\n",
      "binary1: 0.554 | binary2: 0.129\n",
      "Consistency:0.0004\n",
      "Iteration:4500|Loss:0.111\n",
      "Alpha1: 0.271 | Alpha2: 0.277\n",
      "binary1: 0.554 | binary2: 0.129\n",
      "Consistency:0.0004\n",
      "Iteration:4800|Loss:0.111\n",
      "Alpha1: 0.271 | Alpha2: 0.276\n",
      "binary1: 0.554 | binary2: 0.129\n",
      "Consistency:0.0003\n",
      "Iteration:5100|Loss:0.111\n",
      "Alpha1: 0.270 | Alpha2: 0.276\n",
      "binary1: 0.553 | binary2: 0.130\n",
      "Consistency:0.0004\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch2***************\n",
      "epoch:2-LOSS:0.1109\n",
      "Alpha1: 0.270 | Alpha2: 0.275\n",
      "binary1: 0.553 | binary2: 0.130\n",
      "Val RMSPE1:0.3148|Val RMSPE2:0.3048\n",
      "Iteration:0|Loss:0.101\n",
      "Alpha1: 0.241 | Alpha2: 0.247\n",
      "binary1: 0.540 | binary2: 0.107\n",
      "Consistency:0.0003\n",
      "Iteration:300|Loss:0.110\n",
      "Alpha1: 0.265 | Alpha2: 0.271\n",
      "binary1: 0.558 | binary2: 0.133\n",
      "Consistency:0.0003\n",
      "Iteration:600|Loss:0.110\n",
      "Alpha1: 0.267 | Alpha2: 0.271\n",
      "binary1: 0.550 | binary2: 0.133\n",
      "Consistency:0.0004\n",
      "Iteration:900|Loss:0.110\n",
      "Alpha1: 0.267 | Alpha2: 0.272\n",
      "binary1: 0.552 | binary2: 0.130\n",
      "Consistency:0.0004\n",
      "Iteration:1200|Loss:0.110\n",
      "Alpha1: 0.266 | Alpha2: 0.272\n",
      "binary1: 0.551 | binary2: 0.130\n",
      "Consistency:0.0004\n",
      "Iteration:1500|Loss:0.110\n",
      "Alpha1: 0.266 | Alpha2: 0.271\n",
      "binary1: 0.548 | binary2: 0.130\n",
      "Consistency:0.0004\n",
      "Iteration:1800|Loss:0.110\n",
      "Alpha1: 0.267 | Alpha2: 0.274\n",
      "binary1: 0.546 | binary2: 0.131\n",
      "Consistency:0.0003\n",
      "Iteration:2100|Loss:0.110\n",
      "Alpha1: 0.267 | Alpha2: 0.275\n",
      "binary1: 0.545 | binary2: 0.130\n",
      "Consistency:0.0004\n",
      "Iteration:2400|Loss:0.110\n",
      "Alpha1: 0.266 | Alpha2: 0.275\n",
      "binary1: 0.544 | binary2: 0.129\n",
      "Consistency:0.0003\n",
      "Iteration:2700|Loss:0.110\n",
      "Alpha1: 0.266 | Alpha2: 0.274\n",
      "binary1: 0.542 | binary2: 0.130\n",
      "Consistency:0.0002\n",
      "Iteration:3000|Loss:0.109\n",
      "Alpha1: 0.265 | Alpha2: 0.273\n",
      "binary1: 0.541 | binary2: 0.130\n",
      "Consistency:0.0004\n",
      "Iteration:3300|Loss:0.109\n",
      "Alpha1: 0.265 | Alpha2: 0.273\n",
      "binary1: 0.540 | binary2: 0.130\n",
      "Consistency:0.0004\n",
      "Iteration:3600|Loss:0.109\n",
      "Alpha1: 0.264 | Alpha2: 0.272\n",
      "binary1: 0.540 | binary2: 0.130\n",
      "Consistency:0.0003\n",
      "Iteration:3900|Loss:0.109\n",
      "Alpha1: 0.264 | Alpha2: 0.272\n",
      "binary1: 0.539 | binary2: 0.129\n",
      "Consistency:0.0003\n",
      "Iteration:4200|Loss:0.109\n",
      "Alpha1: 0.264 | Alpha2: 0.272\n",
      "binary1: 0.538 | binary2: 0.129\n",
      "Consistency:0.0004\n",
      "Iteration:4500|Loss:0.109\n",
      "Alpha1: 0.264 | Alpha2: 0.271\n",
      "binary1: 0.537 | binary2: 0.129\n",
      "Consistency:0.0003\n",
      "Iteration:4800|Loss:0.108\n",
      "Alpha1: 0.263 | Alpha2: 0.271\n",
      "binary1: 0.535 | binary2: 0.129\n",
      "Consistency:0.0004\n",
      "Iteration:5100|Loss:0.108\n",
      "Alpha1: 0.263 | Alpha2: 0.270\n",
      "binary1: 0.535 | binary2: 0.129\n",
      "Consistency:0.0003\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch3***************\n",
      "epoch:3-LOSS:0.1080\n",
      "Alpha1: 0.263 | Alpha2: 0.270\n",
      "binary1: 0.534 | binary2: 0.129\n",
      "Val RMSPE1:0.2898|Val RMSPE2:0.2830\n",
      "Iteration:0|Loss:0.100\n",
      "Alpha1: 0.244 | Alpha2: 0.266\n",
      "binary1: 0.470 | binary2: 0.106\n",
      "Consistency:0.0003\n",
      "Iteration:300|Loss:0.106\n",
      "Alpha1: 0.258 | Alpha2: 0.264\n",
      "binary1: 0.521 | binary2: 0.133\n",
      "Consistency:0.0004\n",
      "Iteration:600|Loss:0.106\n",
      "Alpha1: 0.259 | Alpha2: 0.266\n",
      "binary1: 0.519 | binary2: 0.133\n",
      "Consistency:0.0004\n",
      "Iteration:900|Loss:0.107\n",
      "Alpha1: 0.259 | Alpha2: 0.267\n",
      "binary1: 0.521 | binary2: 0.133\n",
      "Consistency:0.0004\n",
      "Iteration:1200|Loss:0.106\n",
      "Alpha1: 0.258 | Alpha2: 0.266\n",
      "binary1: 0.522 | binary2: 0.132\n",
      "Consistency:0.0003\n",
      "Iteration:1500|Loss:0.106\n",
      "Alpha1: 0.257 | Alpha2: 0.265\n",
      "binary1: 0.520 | binary2: 0.130\n",
      "Consistency:0.0004\n",
      "Iteration:1800|Loss:0.106\n",
      "Alpha1: 0.259 | Alpha2: 0.267\n",
      "binary1: 0.518 | binary2: 0.128\n",
      "Consistency:0.0003\n",
      "Iteration:2100|Loss:0.106\n",
      "Alpha1: 0.258 | Alpha2: 0.266\n",
      "binary1: 0.518 | binary2: 0.128\n",
      "Consistency:0.0003\n",
      "Iteration:2400|Loss:0.106\n",
      "Alpha1: 0.257 | Alpha2: 0.266\n",
      "binary1: 0.516 | binary2: 0.128\n",
      "Consistency:0.0005\n",
      "Iteration:2700|Loss:0.106\n",
      "Alpha1: 0.257 | Alpha2: 0.266\n",
      "binary1: 0.517 | binary2: 0.128\n",
      "Consistency:0.0003\n",
      "Iteration:3000|Loss:0.105\n",
      "Alpha1: 0.257 | Alpha2: 0.265\n",
      "binary1: 0.516 | binary2: 0.128\n",
      "Consistency:0.0003\n",
      "Iteration:3300|Loss:0.105\n",
      "Alpha1: 0.256 | Alpha2: 0.265\n",
      "binary1: 0.514 | binary2: 0.127\n",
      "Consistency:0.0004\n",
      "Iteration:3600|Loss:0.105\n",
      "Alpha1: 0.256 | Alpha2: 0.264\n",
      "binary1: 0.513 | binary2: 0.127\n",
      "Consistency:0.0004\n",
      "Iteration:3900|Loss:0.105\n",
      "Alpha1: 0.256 | Alpha2: 0.264\n",
      "binary1: 0.513 | binary2: 0.127\n",
      "Consistency:0.0003\n",
      "Iteration:4200|Loss:0.105\n",
      "Alpha1: 0.256 | Alpha2: 0.264\n",
      "binary1: 0.513 | binary2: 0.126\n",
      "Consistency:0.0003\n",
      "Iteration:4500|Loss:0.105\n",
      "Alpha1: 0.255 | Alpha2: 0.264\n",
      "binary1: 0.513 | binary2: 0.126\n",
      "Consistency:0.0004\n",
      "Iteration:4800|Loss:0.105\n",
      "Alpha1: 0.256 | Alpha2: 0.264\n",
      "binary1: 0.512 | binary2: 0.126\n",
      "Consistency:0.0003\n",
      "Iteration:5100|Loss:0.105\n",
      "Alpha1: 0.256 | Alpha2: 0.264\n",
      "binary1: 0.512 | binary2: 0.126\n",
      "Consistency:0.0003\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch4***************\n",
      "epoch:4-LOSS:0.1048\n",
      "Alpha1: 0.255 | Alpha2: 0.264\n",
      "binary1: 0.511 | binary2: 0.126\n",
      "Val RMSPE1:0.2592|Val RMSPE2:0.2666\n",
      "Iteration:0|Loss:0.107\n",
      "Alpha1: 0.229 | Alpha2: 0.228\n",
      "binary1: 0.676 | binary2: 0.124\n",
      "Consistency:0.0004\n",
      "Iteration:300|Loss:0.103\n",
      "Alpha1: 0.248 | Alpha2: 0.257\n",
      "binary1: 0.507 | binary2: 0.130\n",
      "Consistency:0.0003\n",
      "Iteration:600|Loss:0.103\n",
      "Alpha1: 0.251 | Alpha2: 0.261\n",
      "binary1: 0.501 | binary2: 0.129\n",
      "Consistency:0.0004\n",
      "Iteration:900|Loss:0.104\n",
      "Alpha1: 0.252 | Alpha2: 0.263\n",
      "binary1: 0.501 | binary2: 0.127\n",
      "Consistency:0.0003\n",
      "Iteration:1200|Loss:0.104\n",
      "Alpha1: 0.252 | Alpha2: 0.263\n",
      "binary1: 0.503 | binary2: 0.127\n",
      "Consistency:0.0004\n",
      "Iteration:1500|Loss:0.104\n",
      "Alpha1: 0.252 | Alpha2: 0.263\n",
      "binary1: 0.501 | binary2: 0.126\n",
      "Consistency:0.0004\n",
      "Iteration:1800|Loss:0.103\n",
      "Alpha1: 0.252 | Alpha2: 0.262\n",
      "binary1: 0.499 | binary2: 0.125\n",
      "Consistency:0.0004\n",
      "Iteration:2100|Loss:0.103\n",
      "Alpha1: 0.252 | Alpha2: 0.262\n",
      "binary1: 0.501 | binary2: 0.124\n",
      "Consistency:0.0004\n",
      "Iteration:2400|Loss:0.103\n",
      "Alpha1: 0.252 | Alpha2: 0.262\n",
      "binary1: 0.500 | binary2: 0.124\n",
      "Consistency:0.0003\n",
      "Iteration:2700|Loss:0.103\n",
      "Alpha1: 0.252 | Alpha2: 0.262\n",
      "binary1: 0.499 | binary2: 0.124\n",
      "Consistency:0.0003\n",
      "Iteration:3000|Loss:0.103\n",
      "Alpha1: 0.252 | Alpha2: 0.261\n",
      "binary1: 0.499 | binary2: 0.123\n",
      "Consistency:0.0003\n",
      "Iteration:3300|Loss:0.103\n",
      "Alpha1: 0.251 | Alpha2: 0.260\n",
      "binary1: 0.499 | binary2: 0.123\n",
      "Consistency:0.0004\n",
      "Iteration:3600|Loss:0.103\n",
      "Alpha1: 0.251 | Alpha2: 0.261\n",
      "binary1: 0.500 | binary2: 0.124\n",
      "Consistency:0.0004\n",
      "Iteration:3900|Loss:0.103\n",
      "Alpha1: 0.251 | Alpha2: 0.260\n",
      "binary1: 0.500 | binary2: 0.125\n",
      "Consistency:0.0002\n",
      "Iteration:4200|Loss:0.103\n",
      "Alpha1: 0.251 | Alpha2: 0.260\n",
      "binary1: 0.499 | binary2: 0.125\n",
      "Consistency:0.0003\n",
      "Iteration:4500|Loss:0.103\n",
      "Alpha1: 0.251 | Alpha2: 0.260\n",
      "binary1: 0.499 | binary2: 0.125\n",
      "Consistency:0.0002\n",
      "Iteration:4800|Loss:0.103\n",
      "Alpha1: 0.251 | Alpha2: 0.260\n",
      "binary1: 0.498 | binary2: 0.125\n",
      "Consistency:0.0003\n",
      "Iteration:5100|Loss:0.103\n",
      "Alpha1: 0.251 | Alpha2: 0.260\n",
      "binary1: 0.498 | binary2: 0.126\n",
      "Consistency:0.0003\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch5***************\n",
      "epoch:5-LOSS:0.1027\n",
      "Alpha1: 0.250 | Alpha2: 0.259\n",
      "binary1: 0.498 | binary2: 0.125\n",
      "Val RMSPE1:0.2548|Val RMSPE2:0.2619\n",
      "Iteration:0|Loss:0.083\n",
      "Alpha1: 0.224 | Alpha2: 0.224\n",
      "binary1: 0.378 | binary2: 0.060\n",
      "Consistency:0.0004\n",
      "Iteration:300|Loss:0.100\n",
      "Alpha1: 0.243 | Alpha2: 0.250\n",
      "binary1: 0.483 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:600|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.253\n",
      "binary1: 0.496 | binary2: 0.125\n",
      "Consistency:0.0004\n",
      "Iteration:900|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.253\n",
      "binary1: 0.495 | binary2: 0.123\n",
      "Consistency:0.0002\n",
      "Iteration:1200|Loss:0.101\n",
      "Alpha1: 0.247 | Alpha2: 0.253\n",
      "binary1: 0.492 | binary2: 0.122\n",
      "Consistency:0.0003\n",
      "Iteration:1500|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.253\n",
      "binary1: 0.492 | binary2: 0.121\n",
      "Consistency:0.0003\n",
      "Iteration:1800|Loss:0.100\n",
      "Alpha1: 0.246 | Alpha2: 0.252\n",
      "binary1: 0.491 | binary2: 0.121\n",
      "Consistency:0.0003\n",
      "Iteration:2100|Loss:0.100\n",
      "Alpha1: 0.245 | Alpha2: 0.252\n",
      "binary1: 0.490 | binary2: 0.122\n",
      "Consistency:0.0003\n",
      "Iteration:2400|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.253\n",
      "binary1: 0.492 | binary2: 0.123\n",
      "Consistency:0.0003\n",
      "Iteration:2700|Loss:0.101\n",
      "Alpha1: 0.247 | Alpha2: 0.254\n",
      "binary1: 0.492 | binary2: 0.122\n",
      "Consistency:0.0003\n",
      "Iteration:3000|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.254\n",
      "binary1: 0.491 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:3300|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.254\n",
      "binary1: 0.491 | binary2: 0.122\n",
      "Consistency:0.0003\n",
      "Iteration:3600|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.254\n",
      "binary1: 0.492 | binary2: 0.123\n",
      "Consistency:0.0002\n",
      "Iteration:3900|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.254\n",
      "binary1: 0.491 | binary2: 0.122\n",
      "Consistency:0.0003\n",
      "Iteration:4200|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.254\n",
      "binary1: 0.491 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:4500|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.254\n",
      "binary1: 0.490 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:4800|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.254\n",
      "binary1: 0.491 | binary2: 0.122\n",
      "Consistency:0.0004\n",
      "Iteration:5100|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.254\n",
      "binary1: 0.490 | binary2: 0.122\n",
      "Consistency:0.0004\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch6***************\n",
      "epoch:6-LOSS:0.1008\n",
      "Alpha1: 0.246 | Alpha2: 0.254\n",
      "binary1: 0.491 | binary2: 0.123\n",
      "Val RMSPE1:0.2480|Val RMSPE2:0.2517\n",
      "Iteration:0|Loss:0.126\n",
      "Alpha1: 0.257 | Alpha2: 0.264\n",
      "binary1: 0.652 | binary2: 0.314\n",
      "Consistency:0.0002\n",
      "Iteration:300|Loss:0.099\n",
      "Alpha1: 0.240 | Alpha2: 0.249\n",
      "binary1: 0.483 | binary2: 0.118\n",
      "Consistency:0.0003\n",
      "Iteration:600|Loss:0.099\n",
      "Alpha1: 0.241 | Alpha2: 0.249\n",
      "binary1: 0.482 | binary2: 0.119\n",
      "Consistency:0.0002\n",
      "Iteration:900|Loss:0.099\n",
      "Alpha1: 0.242 | Alpha2: 0.249\n",
      "binary1: 0.483 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:1200|Loss:0.099\n",
      "Alpha1: 0.242 | Alpha2: 0.249\n",
      "binary1: 0.483 | binary2: 0.119\n",
      "Consistency:0.0003\n",
      "Iteration:1500|Loss:0.099\n",
      "Alpha1: 0.243 | Alpha2: 0.249\n",
      "binary1: 0.484 | binary2: 0.120\n",
      "Consistency:0.0002\n",
      "Iteration:1800|Loss:0.099\n",
      "Alpha1: 0.243 | Alpha2: 0.250\n",
      "binary1: 0.483 | binary2: 0.121\n",
      "Consistency:0.0003\n",
      "Iteration:2100|Loss:0.099\n",
      "Alpha1: 0.243 | Alpha2: 0.249\n",
      "binary1: 0.483 | binary2: 0.121\n",
      "Consistency:0.0002\n",
      "Iteration:2400|Loss:0.099\n",
      "Alpha1: 0.243 | Alpha2: 0.249\n",
      "binary1: 0.483 | binary2: 0.121\n",
      "Consistency:0.0003\n",
      "Iteration:2700|Loss:0.100\n",
      "Alpha1: 0.243 | Alpha2: 0.251\n",
      "binary1: 0.483 | binary2: 0.121\n",
      "Consistency:0.0002\n",
      "Iteration:3000|Loss:0.100\n",
      "Alpha1: 0.243 | Alpha2: 0.251\n",
      "binary1: 0.485 | binary2: 0.123\n",
      "Consistency:0.0003\n",
      "Iteration:3300|Loss:0.100\n",
      "Alpha1: 0.244 | Alpha2: 0.251\n",
      "binary1: 0.484 | binary2: 0.122\n",
      "Consistency:0.0003\n",
      "Iteration:3600|Loss:0.100\n",
      "Alpha1: 0.245 | Alpha2: 0.252\n",
      "binary1: 0.485 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:3900|Loss:0.100\n",
      "Alpha1: 0.244 | Alpha2: 0.251\n",
      "binary1: 0.484 | binary2: 0.121\n",
      "Consistency:0.0003\n",
      "Iteration:4200|Loss:0.100\n",
      "Alpha1: 0.244 | Alpha2: 0.251\n",
      "binary1: 0.484 | binary2: 0.121\n",
      "Consistency:0.0002\n",
      "Iteration:4500|Loss:0.100\n",
      "Alpha1: 0.244 | Alpha2: 0.251\n",
      "binary1: 0.485 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:4800|Loss:0.100\n",
      "Alpha1: 0.244 | Alpha2: 0.251\n",
      "binary1: 0.485 | binary2: 0.121\n",
      "Consistency:0.0003\n",
      "Iteration:5100|Loss:0.100\n",
      "Alpha1: 0.244 | Alpha2: 0.250\n",
      "binary1: 0.485 | binary2: 0.121\n",
      "Consistency:0.0002\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch7***************\n",
      "epoch:7-LOSS:0.0996\n",
      "Alpha1: 0.244 | Alpha2: 0.250\n",
      "binary1: 0.484 | binary2: 0.121\n",
      "Val RMSPE1:0.2506|Val RMSPE2:0.2490\n",
      "Iteration:0|Loss:0.106\n",
      "Alpha1: 0.261 | Alpha2: 0.258\n",
      "binary1: 0.546 | binary2: 0.110\n",
      "Consistency:0.0002\n",
      "Iteration:300|Loss:0.102\n",
      "Alpha1: 0.250 | Alpha2: 0.261\n",
      "binary1: 0.483 | binary2: 0.127\n",
      "Consistency:0.0003\n",
      "Iteration:600|Loss:0.101\n",
      "Alpha1: 0.246 | Alpha2: 0.255\n",
      "binary1: 0.485 | binary2: 0.123\n",
      "Consistency:0.0002\n",
      "Iteration:900|Loss:0.101\n",
      "Alpha1: 0.248 | Alpha2: 0.255\n",
      "binary1: 0.488 | binary2: 0.123\n",
      "Consistency:0.0004\n",
      "Iteration:1200|Loss:0.101\n",
      "Alpha1: 0.248 | Alpha2: 0.254\n",
      "binary1: 0.487 | binary2: 0.121\n",
      "Consistency:0.0002\n",
      "Iteration:1500|Loss:0.100\n",
      "Alpha1: 0.246 | Alpha2: 0.253\n",
      "binary1: 0.485 | binary2: 0.121\n",
      "Consistency:0.0003\n",
      "Iteration:1800|Loss:0.100\n",
      "Alpha1: 0.246 | Alpha2: 0.252\n",
      "binary1: 0.486 | binary2: 0.121\n",
      "Consistency:0.0002\n",
      "Iteration:2100|Loss:0.100\n",
      "Alpha1: 0.246 | Alpha2: 0.252\n",
      "binary1: 0.486 | binary2: 0.122\n",
      "Consistency:0.0003\n",
      "Iteration:2400|Loss:0.100\n",
      "Alpha1: 0.245 | Alpha2: 0.251\n",
      "binary1: 0.484 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:2700|Loss:0.100\n",
      "Alpha1: 0.245 | Alpha2: 0.251\n",
      "binary1: 0.483 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:3000|Loss:0.100\n",
      "Alpha1: 0.244 | Alpha2: 0.250\n",
      "binary1: 0.483 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:3300|Loss:0.100\n",
      "Alpha1: 0.244 | Alpha2: 0.250\n",
      "binary1: 0.484 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:3600|Loss:0.099\n",
      "Alpha1: 0.243 | Alpha2: 0.250\n",
      "binary1: 0.483 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:3900|Loss:0.099\n",
      "Alpha1: 0.243 | Alpha2: 0.249\n",
      "binary1: 0.483 | binary2: 0.122\n",
      "Consistency:0.0003\n",
      "Iteration:4200|Loss:0.099\n",
      "Alpha1: 0.243 | Alpha2: 0.249\n",
      "binary1: 0.482 | binary2: 0.121\n",
      "Consistency:0.0003\n",
      "Iteration:4500|Loss:0.099\n",
      "Alpha1: 0.243 | Alpha2: 0.249\n",
      "binary1: 0.482 | binary2: 0.120\n",
      "Consistency:0.0003\n",
      "Iteration:4800|Loss:0.099\n",
      "Alpha1: 0.243 | Alpha2: 0.248\n",
      "binary1: 0.480 | binary2: 0.120\n",
      "Consistency:0.0001\n",
      "Iteration:5100|Loss:0.099\n",
      "Alpha1: 0.243 | Alpha2: 0.249\n",
      "binary1: 0.480 | binary2: 0.120\n",
      "Consistency:0.0002\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch8***************\n",
      "epoch:8-LOSS:0.0990\n",
      "Alpha1: 0.243 | Alpha2: 0.248\n",
      "binary1: 0.481 | binary2: 0.120\n",
      "Val RMSPE1:0.2465|Val RMSPE2:0.2535\n",
      "Iteration:0|Loss:0.088\n",
      "Alpha1: 0.225 | Alpha2: 0.225\n",
      "binary1: 0.448 | binary2: 0.066\n",
      "Consistency:0.0002\n",
      "Iteration:300|Loss:0.096\n",
      "Alpha1: 0.238 | Alpha2: 0.242\n",
      "binary1: 0.466 | binary2: 0.108\n",
      "Consistency:0.0002\n",
      "Iteration:600|Loss:0.098\n",
      "Alpha1: 0.241 | Alpha2: 0.247\n",
      "binary1: 0.479 | binary2: 0.117\n",
      "Consistency:0.0003\n",
      "Iteration:900|Loss:0.098\n",
      "Alpha1: 0.241 | Alpha2: 0.247\n",
      "binary1: 0.477 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:1200|Loss:0.098\n",
      "Alpha1: 0.241 | Alpha2: 0.247\n",
      "binary1: 0.477 | binary2: 0.118\n",
      "Consistency:0.0003\n",
      "Iteration:1500|Loss:0.098\n",
      "Alpha1: 0.241 | Alpha2: 0.247\n",
      "binary1: 0.476 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:1800|Loss:0.098\n",
      "Alpha1: 0.242 | Alpha2: 0.247\n",
      "binary1: 0.476 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:2100|Loss:0.098\n",
      "Alpha1: 0.242 | Alpha2: 0.247\n",
      "binary1: 0.476 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:2400|Loss:0.098\n",
      "Alpha1: 0.242 | Alpha2: 0.247\n",
      "binary1: 0.476 | binary2: 0.119\n",
      "Consistency:0.0003\n",
      "Iteration:2700|Loss:0.098\n",
      "Alpha1: 0.242 | Alpha2: 0.247\n",
      "binary1: 0.475 | binary2: 0.119\n",
      "Consistency:0.0003\n",
      "Iteration:3000|Loss:0.098\n",
      "Alpha1: 0.242 | Alpha2: 0.247\n",
      "binary1: 0.475 | binary2: 0.119\n",
      "Consistency:0.0002\n",
      "Iteration:3300|Loss:0.098\n",
      "Alpha1: 0.242 | Alpha2: 0.247\n",
      "binary1: 0.475 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:3600|Loss:0.098\n",
      "Alpha1: 0.242 | Alpha2: 0.247\n",
      "binary1: 0.475 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:3900|Loss:0.098\n",
      "Alpha1: 0.241 | Alpha2: 0.246\n",
      "binary1: 0.474 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:4200|Loss:0.098\n",
      "Alpha1: 0.241 | Alpha2: 0.246\n",
      "binary1: 0.474 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:4500|Loss:0.098\n",
      "Alpha1: 0.241 | Alpha2: 0.246\n",
      "binary1: 0.474 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:4800|Loss:0.098\n",
      "Alpha1: 0.241 | Alpha2: 0.246\n",
      "binary1: 0.474 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:5100|Loss:0.098\n",
      "Alpha1: 0.241 | Alpha2: 0.246\n",
      "binary1: 0.474 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch9***************\n",
      "epoch:9-LOSS:0.0980\n",
      "Alpha1: 0.241 | Alpha2: 0.246\n",
      "binary1: 0.475 | binary2: 0.118\n",
      "Val RMSPE1:0.2443|Val RMSPE2:0.2478\n",
      "Iteration:0|Loss:0.127\n",
      "Alpha1: 0.295 | Alpha2: 0.301\n",
      "binary1: 0.583 | binary2: 0.263\n",
      "Consistency:0.0002\n",
      "Iteration:300|Loss:0.098\n",
      "Alpha1: 0.241 | Alpha2: 0.245\n",
      "binary1: 0.472 | binary2: 0.122\n",
      "Consistency:0.0002\n",
      "Iteration:600|Loss:0.098\n",
      "Alpha1: 0.241 | Alpha2: 0.246\n",
      "binary1: 0.473 | binary2: 0.120\n",
      "Consistency:0.0003\n",
      "Iteration:900|Loss:0.098\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.469 | binary2: 0.120\n",
      "Consistency:0.0002\n",
      "Iteration:1200|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.472 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:1500|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.244\n",
      "binary1: 0.468 | binary2: 0.116\n",
      "Consistency:0.0002\n",
      "Iteration:1800|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.467 | binary2: 0.117\n",
      "Consistency:0.0003\n",
      "Iteration:2100|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.470 | binary2: 0.117\n",
      "Consistency:0.0003\n",
      "Iteration:2400|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.471 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:2700|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.471 | binary2: 0.117\n",
      "Consistency:0.0001\n",
      "Iteration:3000|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.471 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:3300|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.244\n",
      "binary1: 0.471 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:3600|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.472 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:3900|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.472 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:4200|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.471 | binary2: 0.117\n",
      "Consistency:0.0003\n",
      "Iteration:4500|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.471 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:4800|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.471 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:5100|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.471 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch10***************\n",
      "epoch:10-LOSS:0.0975\n",
      "Alpha1: 0.240 | Alpha2: 0.245\n",
      "binary1: 0.471 | binary2: 0.118\n",
      "Val RMSPE1:0.2456|Val RMSPE2:0.2574\n",
      "Iteration:0|Loss:0.086\n",
      "Alpha1: 0.256 | Alpha2: 0.233\n",
      "binary1: 0.366 | binary2: 0.029\n",
      "Consistency:0.0003\n",
      "Iteration:300|Loss:0.098\n",
      "Alpha1: 0.243 | Alpha2: 0.251\n",
      "binary1: 0.461 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:600|Loss:0.098\n",
      "Alpha1: 0.242 | Alpha2: 0.250\n",
      "binary1: 0.462 | binary2: 0.117\n",
      "Consistency:0.0003\n",
      "Iteration:900|Loss:0.098\n",
      "Alpha1: 0.242 | Alpha2: 0.249\n",
      "binary1: 0.464 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:1200|Loss:0.097\n",
      "Alpha1: 0.241 | Alpha2: 0.248\n",
      "binary1: 0.462 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:1500|Loss:0.097\n",
      "Alpha1: 0.242 | Alpha2: 0.248\n",
      "binary1: 0.463 | binary2: 0.116\n",
      "Consistency:0.0002\n",
      "Iteration:1800|Loss:0.098\n",
      "Alpha1: 0.242 | Alpha2: 0.248\n",
      "binary1: 0.466 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:2100|Loss:0.097\n",
      "Alpha1: 0.241 | Alpha2: 0.247\n",
      "binary1: 0.465 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:2400|Loss:0.097\n",
      "Alpha1: 0.241 | Alpha2: 0.246\n",
      "binary1: 0.466 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:2700|Loss:0.097\n",
      "Alpha1: 0.240 | Alpha2: 0.246\n",
      "binary1: 0.464 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:3000|Loss:0.097\n",
      "Alpha1: 0.239 | Alpha2: 0.245\n",
      "binary1: 0.465 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:3300|Loss:0.097\n",
      "Alpha1: 0.239 | Alpha2: 0.245\n",
      "binary1: 0.466 | binary2: 0.117\n",
      "Consistency:0.0001\n",
      "Iteration:3600|Loss:0.097\n",
      "Alpha1: 0.239 | Alpha2: 0.244\n",
      "binary1: 0.467 | binary2: 0.118\n",
      "Consistency:0.0002\n",
      "Iteration:3900|Loss:0.097\n",
      "Alpha1: 0.239 | Alpha2: 0.244\n",
      "binary1: 0.466 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:4200|Loss:0.097\n",
      "Alpha1: 0.239 | Alpha2: 0.244\n",
      "binary1: 0.466 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:4500|Loss:0.097\n",
      "Alpha1: 0.239 | Alpha2: 0.244\n",
      "binary1: 0.465 | binary2: 0.117\n",
      "Consistency:0.0002\n",
      "Iteration:4800|Loss:0.097\n",
      "Alpha1: 0.239 | Alpha2: 0.244\n",
      "binary1: 0.466 | binary2: 0.116\n",
      "Consistency:0.0002\n",
      "Iteration:5100|Loss:0.097\n",
      "Alpha1: 0.239 | Alpha2: 0.244\n",
      "binary1: 0.465 | binary2: 0.116\n",
      "Consistency:0.0003\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch11***************\n",
      "epoch:11-LOSS:0.0968\n",
      "Alpha1: 0.239 | Alpha2: 0.244\n",
      "binary1: 0.466 | binary2: 0.116\n",
      "Val RMSPE1:0.2423|Val RMSPE2:0.2488\n",
      "Iteration:0|Loss:0.088\n",
      "Alpha1: 0.199 | Alpha2: 0.235\n",
      "binary1: 0.443 | binary2: 0.103\n",
      "Consistency:0.0002\n",
      "Iteration:300|Loss:0.095\n",
      "Alpha1: 0.238 | Alpha2: 0.241\n",
      "binary1: 0.455 | binary2: 0.112\n",
      "Consistency:0.0002\n",
      "Iteration:600|Loss:0.095\n",
      "Alpha1: 0.237 | Alpha2: 0.240\n",
      "binary1: 0.451 | binary2: 0.113\n",
      "Consistency:0.0002\n",
      "Iteration:900|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.456 | binary2: 0.112\n",
      "Consistency:0.0002\n",
      "Iteration:1200|Loss:0.095\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.459 | binary2: 0.113\n",
      "Consistency:0.0002\n",
      "Iteration:1500|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.241\n",
      "binary1: 0.459 | binary2: 0.114\n",
      "Consistency:0.0002\n",
      "Iteration:1800|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.460 | binary2: 0.116\n",
      "Consistency:0.0002\n",
      "Iteration:2100|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.461 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:2400|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.460 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:2700|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.460 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:3000|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.242\n",
      "binary1: 0.461 | binary2: 0.116\n",
      "Consistency:0.0002\n",
      "Iteration:3300|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.461 | binary2: 0.116\n",
      "Consistency:0.0003\n",
      "Iteration:3600|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.461 | binary2: 0.116\n",
      "Consistency:0.0002\n",
      "Iteration:3900|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.461 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:4200|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.461 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:4500|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.461 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:4800|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.461 | binary2: 0.116\n",
      "Consistency:0.0002\n",
      "Iteration:5100|Loss:0.096\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.461 | binary2: 0.115\n",
      "Consistency:0.0003\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch12***************\n",
      "epoch:12-LOSS:0.0958\n",
      "Alpha1: 0.237 | Alpha2: 0.241\n",
      "binary1: 0.460 | binary2: 0.115\n",
      "Val RMSPE1:0.2404|Val RMSPE2:0.2425\n",
      "Iteration:0|Loss:0.077\n",
      "Alpha1: 0.204 | Alpha2: 0.206\n",
      "binary1: 0.361 | binary2: 0.055\n",
      "Consistency:0.0002\n",
      "Iteration:300|Loss:0.094\n",
      "Alpha1: 0.233 | Alpha2: 0.238\n",
      "binary1: 0.445 | binary2: 0.119\n",
      "Consistency:0.0002\n",
      "Iteration:600|Loss:0.095\n",
      "Alpha1: 0.234 | Alpha2: 0.239\n",
      "binary1: 0.451 | binary2: 0.116\n",
      "Consistency:0.0001\n",
      "Iteration:900|Loss:0.095\n",
      "Alpha1: 0.235 | Alpha2: 0.240\n",
      "binary1: 0.453 | binary2: 0.116\n",
      "Consistency:0.0003\n",
      "Iteration:1200|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.456 | binary2: 0.115\n",
      "Consistency:0.0003\n",
      "Iteration:1500|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.456 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:1800|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.456 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:2100|Loss:0.095\n",
      "Alpha1: 0.235 | Alpha2: 0.240\n",
      "binary1: 0.455 | binary2: 0.115\n",
      "Consistency:0.0003\n",
      "Iteration:2400|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.455 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:2700|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.455 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:3000|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.454 | binary2: 0.114\n",
      "Consistency:0.0002\n",
      "Iteration:3300|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.453 | binary2: 0.114\n",
      "Consistency:0.0003\n",
      "Iteration:3600|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.453 | binary2: 0.114\n",
      "Consistency:0.0002\n",
      "Iteration:3900|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.453 | binary2: 0.115\n",
      "Consistency:0.0002\n",
      "Iteration:4200|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.453 | binary2: 0.114\n",
      "Consistency:0.0002\n",
      "Iteration:4500|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.453 | binary2: 0.113\n",
      "Consistency:0.0002\n",
      "Iteration:4800|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.240\n",
      "binary1: 0.452 | binary2: 0.113\n",
      "Consistency:0.0002\n",
      "Iteration:5100|Loss:0.095\n",
      "Alpha1: 0.236 | Alpha2: 0.239\n",
      "binary1: 0.452 | binary2: 0.113\n",
      "Consistency:0.0002\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch13***************\n",
      "epoch:13-LOSS:0.0948\n",
      "Alpha1: 0.236 | Alpha2: 0.239\n",
      "binary1: 0.453 | binary2: 0.113\n",
      "Val RMSPE1:0.2401|Val RMSPE2:0.2433\n",
      "Iteration:0|Loss:0.109\n",
      "Alpha1: 0.271 | Alpha2: 0.251\n",
      "binary1: 0.604 | binary2: 0.101\n",
      "Consistency:0.0002\n",
      "Iteration:300|Loss:0.094\n",
      "Alpha1: 0.235 | Alpha2: 0.239\n",
      "binary1: 0.448 | binary2: 0.116\n",
      "Consistency:0.0002\n",
      "Iteration:600|Loss:0.094\n",
      "Alpha1: 0.234 | Alpha2: 0.237\n",
      "binary1: 0.445 | binary2: 0.116\n",
      "Consistency:0.0002\n",
      "Iteration:900|Loss:0.094\n",
      "Alpha1: 0.235 | Alpha2: 0.237\n",
      "binary1: 0.449 | binary2: 0.114\n",
      "Consistency:0.0002\n",
      "Iteration:1200|Loss:0.094\n",
      "Alpha1: 0.233 | Alpha2: 0.236\n",
      "binary1: 0.446 | binary2: 0.112\n",
      "Consistency:0.0002\n",
      "Iteration:1500|Loss:0.094\n",
      "Alpha1: 0.233 | Alpha2: 0.237\n",
      "binary1: 0.447 | binary2: 0.112\n",
      "Consistency:0.0003\n",
      "Iteration:1800|Loss:0.094\n",
      "Alpha1: 0.234 | Alpha2: 0.237\n",
      "binary1: 0.445 | binary2: 0.112\n",
      "Consistency:0.0003\n",
      "Iteration:2100|Loss:0.094\n",
      "Alpha1: 0.234 | Alpha2: 0.237\n",
      "binary1: 0.444 | binary2: 0.112\n",
      "Consistency:0.0002\n",
      "Iteration:2400|Loss:0.094\n",
      "Alpha1: 0.234 | Alpha2: 0.237\n",
      "binary1: 0.445 | binary2: 0.112\n",
      "Consistency:0.0002\n",
      "Iteration:2700|Loss:0.094\n",
      "Alpha1: 0.234 | Alpha2: 0.237\n",
      "binary1: 0.447 | binary2: 0.113\n",
      "Consistency:0.0002\n",
      "Iteration:3000|Loss:0.094\n",
      "Alpha1: 0.234 | Alpha2: 0.238\n",
      "binary1: 0.447 | binary2: 0.113\n",
      "Consistency:0.0002\n",
      "Iteration:3300|Loss:0.094\n",
      "Alpha1: 0.235 | Alpha2: 0.238\n",
      "binary1: 0.447 | binary2: 0.113\n",
      "Consistency:0.0002\n",
      "Iteration:3600|Loss:0.094\n",
      "Alpha1: 0.235 | Alpha2: 0.238\n",
      "binary1: 0.448 | binary2: 0.113\n",
      "Consistency:0.0002\n",
      "Iteration:3900|Loss:0.094\n",
      "Alpha1: 0.235 | Alpha2: 0.238\n",
      "binary1: 0.448 | binary2: 0.113\n",
      "Consistency:0.0003\n",
      "Iteration:4200|Loss:0.094\n",
      "Alpha1: 0.235 | Alpha2: 0.238\n",
      "binary1: 0.447 | binary2: 0.113\n",
      "Consistency:0.0002\n",
      "Iteration:4500|Loss:0.094\n",
      "Alpha1: 0.235 | Alpha2: 0.238\n",
      "binary1: 0.447 | binary2: 0.112\n",
      "Consistency:0.0002\n",
      "Iteration:4800|Loss:0.094\n",
      "Alpha1: 0.235 | Alpha2: 0.238\n",
      "binary1: 0.446 | binary2: 0.112\n",
      "Consistency:0.0002\n",
      "Iteration:5100|Loss:0.094\n",
      "Alpha1: 0.235 | Alpha2: 0.238\n",
      "binary1: 0.446 | binary2: 0.112\n",
      "Consistency:0.0001\n",
      "Evaluating\n",
      "\n",
      "\n",
      "***************End of Epoch14***************\n",
      "epoch:14-LOSS:0.0939\n",
      "Alpha1: 0.235 | Alpha2: 0.238\n",
      "binary1: 0.446 | binary2: 0.111\n",
      "Val RMSPE1:0.2381|Val RMSPE2:0.2402\n"
     ]
    }
   ],
   "source": [
    "max_lr=2e-4\n",
    "optimizer=torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=0.001)\n",
    "schedular=torch.optim.lr_scheduler.OneCycleLR(optimizer,\n",
    "                                              max_lr=max_lr,\n",
    "                                              pct_start=0.15,\n",
    "                                              total_steps= config.epochs * len(train_dataloader)//4,\n",
    "                                              final_div_factor=10)\n",
    "\n",
    "\n",
    "trainer=Trainer(model, train_dataloader, valid_dataloader, optimizer, schedular)\n",
    "trainer.train()\n",
    "#lrs, losses, alpha_losses1, alpha_losses2, consistency_losses=trainer.lr_range_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T13:48:50.008362Z",
     "iopub.status.busy": "2021-09-20T13:48:50.007197Z",
     "iopub.status.idle": "2021-09-20T13:48:50.010406Z",
     "shell.execute_reply": "2021-09-20T13:48:50.010915Z",
     "shell.execute_reply.started": "2021-09-20T03:39:45.405656Z"
    },
    "papermill": {
     "duration": 0.144708,
     "end_time": "2021-09-20T13:48:50.011092",
     "exception": false,
     "start_time": "2021-09-20T13:48:49.866384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#window=8\n",
    "#new_losses=np.array(losses).copy()\n",
    "\n",
    "#cum_x=np.cumsum(new_losses)\n",
    "#x_rolling=(cum_x[window:] - cum_x[:-window])/window\n",
    "#new_losses[window:]=x_rolling\n",
    "\n",
    "#s=300; e=1000\n",
    "\n",
    "#plt.xticks(rotation=45)\n",
    "#plt.plot(lrs[s:e], new_losses[s:e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T13:48:50.302210Z",
     "iopub.status.busy": "2021-09-20T13:48:50.301163Z",
     "iopub.status.idle": "2021-09-20T13:48:50.570631Z",
     "shell.execute_reply": "2021-09-20T13:48:50.571222Z",
     "shell.execute_reply.started": "2021-09-20T03:38:41.614044Z"
    },
    "papermill": {
     "duration": 0.426522,
     "end_time": "2021-09-20T13:48:50.571407",
     "exception": false,
     "start_time": "2021-09-20T13:48:50.144885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(trainer.train_loss, label='loss')\n",
    "plt.plot(trainer.train_alpha1, label='Alpha1')\n",
    "plt.plot(trainer.train_alpha2, label='Alpha2')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.135736,
     "end_time": "2021-09-20T13:48:50.841997",
     "exception": false,
     "start_time": "2021-09-20T13:48:50.706261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T13:48:51.113654Z",
     "iopub.status.busy": "2021-09-20T13:48:51.112870Z",
     "iopub.status.idle": "2021-09-20T13:48:51.118236Z",
     "shell.execute_reply": "2021-09-20T13:48:51.117494Z",
     "shell.execute_reply.started": "2021-09-20T03:38:41.778874Z"
    },
    "papermill": {
     "duration": 0.143594,
     "end_time": "2021-09-20T13:48:51.118388",
     "exception": false,
     "start_time": "2021-09-20T13:48:50.974794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#s=20; e=380\n",
    "\n",
    "#plt.xticks(rotation=45)\n",
    "#plt.plot(lrs[s:e], losses[s:e])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T13:48:51.392574Z",
     "iopub.status.busy": "2021-09-20T13:48:51.391553Z",
     "iopub.status.idle": "2021-09-20T13:48:51.394847Z",
     "shell.execute_reply": "2021-09-20T13:48:51.395487Z",
     "shell.execute_reply.started": "2021-09-20T03:38:41.786618Z"
    },
    "papermill": {
     "duration": 0.141758,
     "end_time": "2021-09-20T13:48:51.395643",
     "exception": false,
     "start_time": "2021-09-20T13:48:51.253885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plt.xticks(rotation=45)\n",
    "#plt.plot(lrs[s:e], alpha_losses1[s:e])\n",
    "#lrs, losses, alpha_losses1, alpha_losses2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T13:48:51.673020Z",
     "iopub.status.busy": "2021-09-20T13:48:51.671839Z",
     "iopub.status.idle": "2021-09-20T13:48:51.675763Z",
     "shell.execute_reply": "2021-09-20T13:48:51.675176Z",
     "shell.execute_reply.started": "2021-09-20T03:38:41.794015Z"
    },
    "papermill": {
     "duration": 0.142623,
     "end_time": "2021-09-20T13:48:51.675899",
     "exception": false,
     "start_time": "2021-09-20T13:48:51.533276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#plt.xticks(rotation=45)\n",
    "#plt.plot(lrs[s:e], alpha_losses2[s:e])\n",
    "#lrs, losses, alpha_losses1, alpha_losses2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-20T13:48:51.954909Z",
     "iopub.status.busy": "2021-09-20T13:48:51.953768Z",
     "iopub.status.idle": "2021-09-20T13:48:51.957270Z",
     "shell.execute_reply": "2021-09-20T13:48:51.956689Z",
     "shell.execute_reply.started": "2021-09-20T03:38:41.801665Z"
    },
    "papermill": {
     "duration": 0.145583,
     "end_time": "2021-09-20T13:48:51.957429",
     "exception": false,
     "start_time": "2021-09-20T13:48:51.811846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#plt.xticks(rotation=45)\n",
    "#plt.plot(lrs[s:e], consistency_losses[s:e])\n",
    "#lrs, losses, alpha_losses1, alpha_losses2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.134533,
     "end_time": "2021-09-20T13:48:52.227480",
     "exception": false,
     "start_time": "2021-09-20T13:48:52.092947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27143.347381,
   "end_time": "2021-09-20T13:48:55.834823",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-20T06:16:32.487442",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
