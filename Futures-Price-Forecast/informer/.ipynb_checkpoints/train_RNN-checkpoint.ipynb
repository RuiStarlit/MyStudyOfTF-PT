{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import glob\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from utils import *\n",
    "from models import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_RNN import *\n",
    "assert torch.cuda.is_available()\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = glob.glob('../stock_price/train/*.hdf')\n",
    "train_f.remove('../stock_price/train/20190425_20190510.hdf')\n",
    "test_f = glob.glob('../stock_price/test/*.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../stock_price/train/20190523_20190604.hdf',\n",
       " '../stock_price/train/20190412_20190424.hdf',\n",
       " '../stock_price/train/20190604_20190617.hdf',\n",
       " '../stock_price/train/20190710_20190723.hdf',\n",
       " '../stock_price/train/20190723_20190731.hdf',\n",
       " '../stock_price/train/20190510_20190522.hdf',\n",
       " '../stock_price/train/20190628_20190710.hdf',\n",
       " '../stock_price/train/20190617_20190628.hdf',\n",
       " '../stock_price/train/20190401_20190412.hdf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = ['../stock_price/train/20190401_20190412.hdf',\n",
    "'../stock_price/train/20190412_20190424.hdf',\n",
    "'../stock_price/train/20190510_20190522.hdf',\n",
    "'../stock_price/train/20190523_20190604.hdf',\n",
    "'../stock_price/train/20190604_20190617.hdf',\n",
    "'../stock_price/train/20190617_20190628.hdf',\n",
    "'../stock_price/train/20190628_20190710.hdf',\n",
    "'../stock_price/train/20190710_20190723.hdf',\n",
    "'../stock_price/train/20190723_20190731.hdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_index = random.sample(range(0,173),20)\n",
    "test_index = [148,167,94,66,13,70,19,21,44,149,115,56,35,161,109,101,68,111,45,34]\n",
    "test_f = np.array(test_f)[test_index]\n",
    "test_f = test_f.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams\n",
    "enc_in = 15\n",
    "dec_in = 1\n",
    "c_out = 1 \n",
    "seq_len = 20\n",
    "out_len = 5\n",
    "d_model = 16\n",
    "d_ff = 8\n",
    "n_heads = 2\n",
    "label_len = 10\n",
    "e_layers = 3\n",
    "d_layers = 2\n",
    "\n",
    "dropout = 0.1\n",
    "batch_size = 512\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = Train_RNN(enc_in, dec_in, c_out, seq_len, out_len, d_model, d_ff, n_heads, \n",
    "                                e_layers, d_layers, label_len,\n",
    "                                dropout, batch_size, lr, device, train_f, test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informer(\n",
      "  (enc_embedding): DataEmbedding(\n",
      "    (value_embedding): TokenEmbedding(\n",
      "      (tokenConv): Conv1d(15, 16, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
      "    )\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (dec_embedding): DataEmbedding(\n",
      "    (value_embedding): TokenEmbedding(\n",
      "      (tokenConv): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
      "    )\n",
      "    (position_embedding): PositionalEmbedding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (attn_layers): ModuleList(\n",
      "      (0): EncoderLayer(\n",
      "        (attention): AttentionLayer(\n",
      "          (inner_attention): ProbAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (out_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): EncoderLayer(\n",
      "        (attention): AttentionLayer(\n",
      "          (inner_attention): ProbAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (out_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): EncoderLayer(\n",
      "        (attention): AttentionLayer(\n",
      "          (inner_attention): ProbAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (out_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): ConvLayer(\n",
      "        (downConv): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ELU(alpha=1.0)\n",
      "        (maxPool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (1): ConvLayer(\n",
      "        (downConv): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), padding_mode=circular)\n",
      "        (norm): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ELU(alpha=1.0)\n",
      "        (maxPool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): DecoderLayer(\n",
      "        (self_attention): AttentionLayer(\n",
      "          (inner_attention): ProbAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (out_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (cross_attention): AttentionLayer(\n",
      "          (inner_attention): FullAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (out_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): DecoderLayer(\n",
      "        (self_attention): AttentionLayer(\n",
      "          (inner_attention): ProbAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (out_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (cross_attention): AttentionLayer(\n",
      "          (inner_attention): FullAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (query_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (key_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (value_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "          (out_projection): Linear(in_features=16, out_features=16, bias=True)\n",
      "        )\n",
      "        (conv1): Conv1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "        (conv2): Conv1d(8, 16, kernel_size=(1,), stride=(1,))\n",
      "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (projection): Linear(in_features=16, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "RNN._build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN._selct_optim('sgd')\n",
    "RNN._selct_scheduler(10,0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_name = '../stock_price/train/20190523_20190604.hdf'\n",
    "test_file_name = '../stock_price/test/IC2003_20190807.hdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c03a027162441faac8f76a1794b8884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1 |Train_Loss:1.451845 |R2:0.415372|Val_Loss:1.133462 |R2:0.264814 |Rate:0.671 |lr:0.001000\n",
      "Epoch:  2 |Train_Loss:1.440371 |R2:0.414571|Val_Loss:1.135017 |R2:0.263483 |Rate:0.668 |lr:0.001000\n",
      "Epoch:  3 |Train_Loss:1.439760 |R2:0.416478|Val_Loss:1.134108 |R2:0.274692 |Rate:0.672 |lr:0.001000\n",
      "Epoch:  4 |Train_Loss:1.440152 |R2:0.415100|Val_Loss:1.134850 |R2:0.244815 |Rate:0.667 |lr:0.001000\n",
      "Epoch:  5 |Train_Loss:1.439453 |R2:0.417879|Val_Loss:1.136220 |R2:0.217223 |Rate:0.664 |lr:0.001000\n",
      "Epoch:  6 |Train_Loss:1.439504 |R2:0.417597|Val_Loss:1.134118 |R2:0.250703 |Rate:0.672 |lr:0.001000\n",
      "Epoch:  7 |Train_Loss:1.439631 |R2:0.417302|Val_Loss:1.134063 |R2:0.245618 |Rate:0.669 |lr:0.001000\n",
      "Epoch:  8 |Train_Loss:1.439318 |R2:0.418408|Val_Loss:1.135195 |R2:0.229901 |Rate:0.671 |lr:0.001000\n",
      "Epoch:  9 |Train_Loss:1.439751 |R2:0.417072|Val_Loss:1.134060 |R2:0.250714 |Rate:0.665 |lr:0.001000\n",
      "Epoch: 10 |Train_Loss:1.439444 |R2:0.417852|Val_Loss:1.132227 |R2:0.259571 |Rate:0.672 |lr:0.001000\n",
      "Epoch: 11 |Train_Loss:1.439451 |R2:0.418296|Val_Loss:1.133878 |R2:0.258236 |Rate:0.668 |lr:0.001000\n",
      "Epoch: 12 |Train_Loss:1.439284 |R2:0.418365|Val_Loss:1.134694 |R2:0.254261 |Rate:0.667 |lr:0.001000\n",
      "Epoch: 13 |Train_Loss:1.439541 |R2:0.417473|Val_Loss:1.133667 |R2:0.259688 |Rate:0.667 |lr:0.001000\n",
      "Epoch: 14 |Train_Loss:1.439190 |R2:0.418952|Val_Loss:1.134515 |R2:0.258011 |Rate:0.667 |lr:0.001000\n",
      "Epoch: 15 |Train_Loss:1.439341 |R2:0.417959|Val_Loss:1.134080 |R2:0.244431 |Rate:0.670 |lr:0.001000\n",
      "Epoch: 16 |Train_Loss:1.439891 |R2:0.415959|Val_Loss:1.133136 |R2:0.274898 |Rate:0.671 |lr:0.001000\n",
      "Epoch: 17 |Train_Loss:1.439326 |R2:0.418073|Val_Loss:1.132620 |R2:0.274700 |Rate:0.672 |lr:0.001000\n",
      "Epoch: 18 |Train_Loss:1.439219 |R2:0.418532|Val_Loss:1.132975 |R2:0.274120 |Rate:0.671 |lr:0.001000\n",
      "Epoch: 19 |Train_Loss:1.439230 |R2:0.418609|Val_Loss:1.135043 |R2:0.234740 |Rate:0.668 |lr:0.001000\n",
      "Epoch: 20 |Train_Loss:1.439594 |R2:0.417074|Val_Loss:1.134064 |R2:0.282529 |Rate:0.672 |lr:0.001000\n",
      "Epoch: 21 |Train_Loss:1.439023 |R2:0.419127|Val_Loss:1.135378 |R2:0.255608 |Rate:0.667 |lr:0.001000\n",
      "Epoch: 22 |Train_Loss:1.439047 |R2:0.418837|Val_Loss:1.135648 |R2:0.237471 |Rate:0.668 |lr:0.001000\n",
      "Epoch: 23 |Train_Loss:1.439150 |R2:0.418829|Val_Loss:1.136266 |R2:0.218672 |Rate:0.663 |lr:0.001000\n",
      "Epoch: 24 |Train_Loss:1.438973 |R2:0.419484|Val_Loss:1.134086 |R2:0.241914 |Rate:0.666 |lr:0.001000\n",
      "Epoch: 25 |Train_Loss:1.439103 |R2:0.418593|Val_Loss:1.134979 |R2:0.227378 |Rate:0.664 |lr:0.001000\n",
      "Epoch: 26 |Train_Loss:1.439038 |R2:0.419605|Val_Loss:1.133653 |R2:0.262755 |Rate:0.673 |lr:0.001000\n",
      "Epoch: 27 |Train_Loss:1.439639 |R2:0.416765|Val_Loss:1.132822 |R2:0.279488 |Rate:0.673 |lr:0.001000\n",
      "Epoch: 28 |Train_Loss:1.439568 |R2:0.416981|Val_Loss:1.135513 |R2:0.247101 |Rate:0.669 |lr:0.001000\n",
      "Epoch: 29 |Train_Loss:1.438958 |R2:0.419542|Val_Loss:1.135764 |R2:0.244892 |Rate:0.671 |lr:0.001000\n",
      "Epoch: 30 |Train_Loss:1.439064 |R2:0.419275|Val_Loss:1.135166 |R2:0.242257 |Rate:0.667 |lr:0.001000\n",
      "Epoch: 31 |Train_Loss:1.438923 |R2:0.419500|Val_Loss:1.135260 |R2:0.242697 |Rate:0.667 |lr:0.001000\n",
      "Epoch: 32 |Train_Loss:1.438876 |R2:0.419913|Val_Loss:1.135591 |R2:0.236874 |Rate:0.664 |lr:0.001000\n",
      "Epoch: 33 |Train_Loss:1.438888 |R2:0.419481|Val_Loss:1.137726 |R2:0.213842 |Rate:0.663 |lr:0.001000\n",
      "Epoch: 34 |Train_Loss:1.438711 |R2:0.420186|Val_Loss:1.134778 |R2:0.251898 |Rate:0.671 |lr:0.001000\n",
      "Epoch: 35 |Train_Loss:1.440034 |R2:0.414598|Val_Loss:1.132009 |R2:0.312824 |Rate:0.675 |lr:0.001000\n",
      "Epoch: 36 |Train_Loss:1.439497 |R2:0.417239|Val_Loss:1.132542 |R2:0.306455 |Rate:0.675 |lr:0.001000\n",
      "Epoch: 37 |Train_Loss:1.438845 |R2:0.419717|Val_Loss:1.134585 |R2:0.269326 |Rate:0.668 |lr:0.001000\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-95c86ede2057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m Informer.train(epochs=200, train_all=False, f=train_file_name,\n\u001b[0;32m----> 2\u001b[0;31m              val_all=True, testfile=test_file_name, save='train')\n\u001b[0m",
      "\u001b[0;32m/home/jovyan/quant/informer/train_Informer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, train_all, f, val_all, testfile, save)\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mval_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mtrain_r2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jovyan/quant/informer/train_Informer.py\u001b[0m in \u001b[0;36mval\u001b[0;34m(self, val_all, f)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RNN.train(epochs=100, train_all=False, f=train_file_name,\n",
    "             val_all=False, testfile=test_file_name, save='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
